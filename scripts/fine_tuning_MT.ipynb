{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ProcessingPool' from 'torch.multiprocessing' (/home/mmasood1/.conda/envs/molbert/lib/python3.7/site-packages/torch/multiprocessing/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6637/502100652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessingPool\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ProcessingPool' from 'torch.multiprocessing' (/home/mmasood1/.conda/envs/molbert/lib/python3.7/site-packages/torch/multiprocessing/__init__.py)"
     ]
    }
   ],
   "source": [
    "from torch.multiprocessing import ProcessingPool as Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, yaml\n",
    "from argparse import Namespace\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, StepLR\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_constant_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    )\n",
    "\n",
    "import wandb\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "wandb.login(key = \"27edf9c66b032c03f72d30e923276b93aa736429\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molbert.models.finetune import FinetuneSmilesMolbertModel\n",
    "from molbert.datasets.dataloading import MolbertDataLoader\n",
    "from molbert.datasets.finetune import BertFinetuneSmilesDataset_MF\n",
    "from molbert.datasets.finetune import BertFinetuneSmilesDataset\n",
    "\n",
    "from molbert.utils.featurizer.molfeaturizer import SmilesIndexFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hidden_block(nn.Module):\n",
    "    def __init__(self,input_dim, hidden_dim, BatchNorm1d, dropout_p, use_skip_connection):\n",
    "        super(Hidden_block, self).__init__()\n",
    "        self.use_batch_norm = BatchNorm1d\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            self.batchnorm1 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        x2 = self.layer1(x1)\n",
    "\n",
    "        if self.use_batch_norm:\n",
    "            x2 = self.batchnorm1(x2) \n",
    "\n",
    "        if self.use_skip_connection:\n",
    "            x2 = x2 + x1             # Add skip connection\n",
    "            \n",
    "        x_out = torch.relu(x2)       # apply activation after addition\n",
    "        x_out = self.dropout(x_out)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolbertModel(pl.LightningModule):\n",
    "    def __init__(self, args: Namespace):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.training_step_ytrue, self.training_step_ypred = [],[]\n",
    "        self.val_step_ytrue, self.val_step_ypred = [],[]\n",
    "\n",
    "        self.hparams = args\n",
    "        self.get_creterian(args)\n",
    "\n",
    "        # get model, load pretrained weights, and freeze encoder\n",
    "        self.encoder = FinetuneSmilesMolbertModel(self.hparams)\n",
    "        checkpoint = torch.load(self.hparams.pretrained_model_path, map_location=lambda storage, loc: storage)\n",
    "        self.encoder.load_state_dict(checkpoint['state_dict'], strict = False)\n",
    "        # Freeze model\n",
    "        MolbertModel.freeze_network(self.encoder, self.hparams.freeze_level)\n",
    "        self.encoder = self.encoder.model.bert\n",
    "\n",
    "        # Model architecture\n",
    "        self.input_layer = nn.Linear(self.hparams.input_dim, self.hparams.hidden_dim)\n",
    "        self.Hidden_block = nn.ModuleList([Hidden_block(self.hparams.hidden_dim, \n",
    "                                                        self.hparams.hidden_dim, \n",
    "                                                        self.hparams.BatchNorm1d, \n",
    "                                                        self.hparams.dropout_p,\n",
    "                                                        self.hparams.use_skip_connection\n",
    "                                                        ) for _ in range(self.hparams.depth)])\n",
    "        self.output_layer = nn.Linear(self.hparams.hidden_dim, self.hparams.num_of_tasks)\n",
    "        \n",
    "        # dropout and Batchnorm for first layer output\n",
    "        self.dropout = nn.Dropout(self.hparams.dropout_p)\n",
    "        if self.hparams.BatchNorm1d:\n",
    "            self.batchnorm1 = nn.BatchNorm1d(self.hparams.hidden_dim)\n",
    "        \n",
    "    def forward(self, batch_inputs):\n",
    "        input_ids =  batch_inputs[\"input_ids\"]\n",
    "        token_type_ids = batch_inputs[\"token_type_ids\"]\n",
    "        attention_mask = batch_inputs[\"attention_mask\"]\n",
    "\n",
    "        _, pooled_output = self.encoder(input_ids, token_type_ids, attention_mask)\n",
    "        x1 = self.input_layer(pooled_output)\n",
    "        if self.hparams.BatchNorm1d:\n",
    "            x1 = self.batchnorm1(x1)\n",
    "        x1 = torch.relu(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        \n",
    "        for block in self.Hidden_block:\n",
    "            x_n = block(x1)  # Apply each Hidden block\n",
    "        logits = self.output_layer(x_n)\n",
    "        return logits\n",
    "    \n",
    "    def get_creterian(self, config):\n",
    "        # pos weights\n",
    "        \n",
    "        pos_weights = pd.read_csv(config[\"pos_weights\"])\n",
    "        if self.hparams.num_of_tasks == 1:\n",
    "            pos_weights = pos_weights.set_index(\"Targets\").reindex([config[\"selected_tasks\"]]).weights.values\n",
    "        else:\n",
    "            pos_weights = pos_weights.set_index(\"Targets\").reindex(config[\"selected_tasks\"]).weights.values\n",
    "        pos_weights = (config[\"alpha\"] * pos_weights) + (1 - config[\"alpha\"])*1\n",
    "        self.pos_weights = torch.tensor(pos_weights, device = config[\"device\"])\n",
    "\n",
    "        # class weights\n",
    "        if self.hparams.num_of_tasks > 1:\n",
    "            class_weights = pd.read_csv(config[\"class_weights\"])\n",
    "            class_weights = class_weights.set_index(\"Targets\").reindex(config[\"selected_tasks\"]).weights.values\n",
    "            class_weights = (config[\"beta\"] * class_weights) + (1 - config[\"beta\"])*1\n",
    "            self.class_weights = torch.tensor(class_weights, device = config[\"device\"])\n",
    "        else:\n",
    "            self.class_weights = torch.tensor([1.0], device = config[\"device\"])\n",
    "\n",
    "        # train_weighted loss, validation no weights\n",
    "        self.weighted_creterien =  nn.BCEWithLogitsLoss(reduction=\"none\", \n",
    "                                                        pos_weight= self.pos_weights,\n",
    "                                                        weight= self.class_weights)\n",
    "        \n",
    "        self.non_weighted_creterian =  nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "    def add_weight_decay(self, skip_list=()):\n",
    "        decay = []\n",
    "        no_decay = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            if len(param.shape) == 1 or name in skip_list:\n",
    "                no_decay.append(param)\n",
    "            else:\n",
    "                decay.append(param)\n",
    "            \n",
    "        return [\n",
    "            {'params': no_decay, 'weight_decay': 0.},\n",
    "            {'params': decay, 'weight_decay': self.hparams.l2_lambda}]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_grouped_parameters = self.add_weight_decay(skip_list=())\n",
    "\n",
    "        if self.hparams.optim == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(optimizer_grouped_parameters, \n",
    "                                             lr=self.hparams.learning_rate)\n",
    "        if self.hparams.optim == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(optimizer_grouped_parameters, \n",
    "                                             lr=self.hparams.learning_rate)\n",
    "        if self.hparams.optim == 'AdamW':    \n",
    "            self.optimizer = AdamW(optimizer_grouped_parameters, \n",
    "                                lr=self.hparams.learning_rate, \n",
    "                                eps=self.hparams.adam_epsilon)\n",
    "        \n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, \n",
    "                                                                        T_max = 10, \n",
    "                                                                        eta_min=1e-6)\n",
    "        return {\"optimizer\": self.optimizer, \n",
    "                \"lr_scheduler\": self.scheduler}\n",
    "\n",
    "    def compute_regularization(self):\n",
    "        device = torch.device('cuda')\n",
    "        encoder_reg = torch.tensor(0., requires_grad=True, device=device)\n",
    "        task_emb_reg = torch.tensor(0., requires_grad=True, device=device)\n",
    "\n",
    "        # l2: Apply only on weights, exclude bias\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                encoder_reg = encoder_reg + torch.norm(param, p=2)\n",
    "\n",
    "        # l1: Apply only on weights, exclude bias\n",
    "        for name, param in self.task_embedding.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                task_emb_reg = task_emb_reg + torch.norm(param, p=1)\n",
    "                \n",
    "        return encoder_reg, task_emb_reg\n",
    "    \n",
    "    def _compute_loss(self, y, y_hat):\n",
    "        if self.hparams.num_of_tasks == 1:\n",
    "            y = y.unsqueeze(1)\n",
    "        # compute losses, wiht masking\n",
    "        if self.hparams.missing == 'nan':\n",
    "            nan_mask = torch.isnan(y)\n",
    "            y[nan_mask] = -1\n",
    "            #y = torch.nan_to_num(y, nan = -1), for newer version\n",
    "        \n",
    "        # masks\n",
    "        valid_label_mask = (y != -1).float()\n",
    "        pos_label_mask = (y == 1)\n",
    "        negative_label_mask = (y == 0)\n",
    "\n",
    "        weighted_loss = self.weighted_creterien(y_hat, y) * valid_label_mask\n",
    "        Non_weighted_loss = self.non_weighted_creterian(y_hat, y) * valid_label_mask\n",
    "        \n",
    "        # Non_weighted_loss, positive negative loss\n",
    "        pos_loss = Non_weighted_loss * pos_label_mask\n",
    "        neg_loss = Non_weighted_loss * negative_label_mask\n",
    "        pos_loss = pos_loss.sum() / pos_label_mask.sum()\n",
    "        neg_loss = neg_loss.sum() / negative_label_mask.sum()\n",
    "    \n",
    "        # compute mean loss\n",
    "        Non_weighted_loss = Non_weighted_loss.sum() / valid_label_mask.sum()\n",
    "        weighted_loss = weighted_loss.sum() / valid_label_mask.sum()\n",
    "\n",
    "        return weighted_loss, Non_weighted_loss, pos_loss, neg_loss\n",
    "    \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # compute forward pass\n",
    "        (batch_inputs, batch_labels), _ = batch\n",
    "        y = batch_labels[\"finetune\"].squeeze()\n",
    "        y_hat = self.forward(batch_inputs)\n",
    "\n",
    "        # compute loss\n",
    "        weighted_loss, Non_weighted_loss, pos_loss, neg_loss = self._compute_loss(y, y_hat)  \n",
    "        self.training_step_ytrue.append(y.long().cpu())\n",
    "        self.training_step_ypred.append(torch.sigmoid(y_hat).cpu())\n",
    "\n",
    "        return {\"loss\": weighted_loss,\n",
    "                \"weighted_loss\":weighted_loss,\n",
    "                \"Non_weighted_loss\":Non_weighted_loss,\n",
    "                \"pos_loss\":pos_loss, \n",
    "                \"neg_loss\":neg_loss\n",
    "                }\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # compute forward pass\n",
    "        (batch_inputs, batch_labels), _ = batch\n",
    "        y = batch_labels[\"finetune\"].squeeze()\n",
    "        y_hat = self.forward(batch_inputs)\n",
    "\n",
    "\n",
    "        # compute loss\n",
    "        weighted_loss, Non_weighted_loss, pos_loss, neg_loss = self._compute_loss(y, y_hat)  \n",
    "        self.val_step_ytrue.append(y.long().cpu())\n",
    "        self.val_step_ypred.append(torch.sigmoid(y_hat).cpu())\n",
    "        return {\"loss\": weighted_loss,\n",
    "                \"weighted_loss\":weighted_loss,\n",
    "                \"Non_weighted_loss\":Non_weighted_loss,\n",
    "                \"pos_loss\":pos_loss, \n",
    "                \"neg_loss\":neg_loss\n",
    "                }\n",
    "    \n",
    "    def on_epoch_start(self):\n",
    "        # Check if current epoch is greater than or equal to the desired epoch to unfreeze\n",
    "        if self.current_epoch >= self.hparams.unfreeze_epoch:\n",
    "            self.unfreeze_model()\n",
    "\n",
    "            # Decrease the learning rate\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = self.hparams.BERT_lr\n",
    "            \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, \n",
    "                                                                        last_epoch = self.scheduler.last_epoch,\n",
    "                                                                        T_max = 10, \n",
    "                                                                        eta_min=1e-6)\n",
    "                \n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_weighted_loss = torch.stack([x['weighted_loss'] for x in outputs]).mean()\n",
    "        avg_non_weighted_loss = torch.stack([x['Non_weighted_loss'] for x in outputs]).mean()\n",
    "        avg_pos_loss = torch.stack([x['pos_loss'] for x in outputs]).mean()\n",
    "        avg_neg_loss = torch.stack([x['neg_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\n",
    "                    'train_total_loss': avg_loss,\n",
    "                    'train_weighted_loss': avg_weighted_loss,\n",
    "                    'train_Non_weighted_loss': avg_non_weighted_loss,\n",
    "                    'train_pos_loss': avg_pos_loss,\n",
    "                    'train_neg_loss': avg_neg_loss\n",
    "                    }\n",
    "        wandb.log(tensorboard_logs)\n",
    "\n",
    "        # Log the learning rate at the end of each epoch\n",
    "        lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        wandb.log({'learning_rate': lr})\n",
    "        \n",
    "        # Collect predictions and true labels for the complete training set\n",
    "        train_true = torch.cat(self.training_step_ytrue, dim=0)\n",
    "        train_preds = torch.cat(self.training_step_ypred, dim=0)\n",
    "\n",
    "        score_list =  self.compute_metrics(train_true, train_preds)\n",
    "        metric = ['roc_score', 'blc_acc', 'sensitivity', 'specificity', 'AUPR']\n",
    "            \n",
    "        for i, score in enumerate(score_list):\n",
    "                wandb.log({f'train_{metric[i]}':score.item()})\n",
    "        \n",
    "        # Clear the lists to free memory for the next epoch\n",
    "        self.training_step_ytrue.clear()\n",
    "        self.training_step_ypred.clear()\n",
    "        del train_true,train_preds\n",
    "\n",
    "        return {\"avg_loss\":avg_loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_weighted_loss = torch.stack([x['weighted_loss'] for x in outputs]).mean()\n",
    "        avg_non_weighted_loss = torch.stack([x['Non_weighted_loss'] for x in outputs]).mean()\n",
    "        avg_pos_loss = torch.stack([x['pos_loss'] for x in outputs]).mean()\n",
    "        avg_neg_loss = torch.stack([x['neg_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\n",
    "                    'val_total_loss': avg_loss,\n",
    "                    'val_weighted_loss': avg_weighted_loss,\n",
    "                    'val_Non_weighted_loss': avg_non_weighted_loss,\n",
    "                    'val_pos_loss': avg_pos_loss,\n",
    "                    'val_neg_loss': avg_neg_loss\n",
    "                    }\n",
    "        wandb.log(tensorboard_logs)\n",
    "\n",
    "        #Collect predictions and true labels for the complete training set\n",
    "        val_true = torch.cat(self.val_step_ytrue, dim=0)\n",
    "        val_preds = torch.cat(self.val_step_ypred, dim=0)\n",
    "\n",
    "        score_list =  self.compute_metrics(val_true,val_preds)\n",
    "        metric = ['roc_score', 'blc_acc', 'sensitivity', 'specificity', 'AUPR']\n",
    "            \n",
    "        for i, score in enumerate(score_list):\n",
    "            wandb.log({f'val_{metric[i]}':score.item()})\n",
    "\n",
    "        # Clear the lists to free memory for the next epoch\n",
    "        self.val_step_ytrue.clear()\n",
    "        self.val_step_ypred.clear()\n",
    "        del val_true, val_preds\n",
    "\n",
    "    def compute_metrics(self, y_true, y_pred): \n",
    "        self.eval()\n",
    "\n",
    "        targets =  y_true.cpu().detach().tolist()\n",
    "        preds = y_pred.cpu().detach().tolist()\n",
    "\n",
    "        targets = np.array(targets).reshape(-1,self.hparams.num_of_tasks)\n",
    "        preds = np.array(preds).reshape(-1,self.hparams.num_of_tasks)\n",
    "\n",
    "        #if self.hparams.missing == 'nan':\n",
    "        #    mask = ~np.isnan(targets)\n",
    "        \n",
    "        mask = (targets != -1)\n",
    "\n",
    "        roc_score, blc_acc, sensitivity, specificity, AUPR, f1_score, average_precision = [],[],[],[],[],[],[]\n",
    "        for i in range(self.hparams.num_of_tasks):\n",
    "                \n",
    "                # get valid targets, and convert logits to prob\n",
    "                valid_targets = targets[:,i][mask[:,i]]\n",
    "                valid_preds = expit(preds[:,i][mask[:,i]])\n",
    "                try:\n",
    "                    # ROC_AUC\n",
    "                    fpr, tpr, th = roc_curve(valid_targets, valid_preds)\n",
    "                    roc_score.append(auc(fpr, tpr))\n",
    "\n",
    "                    # Balanced accuracy\n",
    "                    balanced_accuracy = (tpr + (1 - fpr)) / 2\n",
    "                    blc_acc.append(np.max(balanced_accuracy))\n",
    "\n",
    "                    # sensitivity, specificity\n",
    "                    optimal_threshold_index = np.argmax(balanced_accuracy)\n",
    "                    optimal_threshold = th[optimal_threshold_index]\n",
    "                    sensitivity.append(tpr[optimal_threshold_index])\n",
    "                    specificity.append(1 - fpr[optimal_threshold_index])\n",
    "\n",
    "                    # AUPR, F1\n",
    "                    precision, recall, thresholds = precision_recall_curve(valid_targets, valid_preds)\n",
    "                    AUPR.append(auc(recall, precision))\n",
    "                    \n",
    "                except:\n",
    "                    roc_score.append(np.nan)\n",
    "                    #print('Performance metric is null')\n",
    "                \n",
    "        self.train()\n",
    "        return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR)\n",
    "\n",
    "    \n",
    "    def prob_to_labels(self, pred, threshold):\n",
    "\t    return (pred >= threshold).astype('int')\n",
    "\n",
    "    def unfreeze_model(self):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    @staticmethod\n",
    "    def freeze_network(model, freeze_level: int):\n",
    "        \"\"\"\n",
    "        Freezes specific layers of the model depending on the freeze_level argument:\n",
    "\n",
    "         0: freeze nothing\n",
    "        -1: freeze all BERT weights but not the task head\n",
    "        -2: freeze the pooling layer\n",
    "        -3: freeze the embedding layer\n",
    "        -4: freeze the task head but not the base layer\n",
    "        n>0: freeze the bottom n layers of the base model.\n",
    "        \"\"\"\n",
    "\n",
    "        model_bert = model.model.bert\n",
    "        model_tasks = model.model.tasks\n",
    "\n",
    "        model_bert_encoder = model.model.bert.encoder\n",
    "        model_bert_pooler = model.model.bert.pooler\n",
    "        model_bert_embeddings = model.model.bert.embeddings\n",
    "\n",
    "        if freeze_level == 0:\n",
    "            # freeze nothing\n",
    "            return\n",
    "\n",
    "        elif freeze_level > 0:\n",
    "            # freeze the encoder/transformer\n",
    "            n_encoder_layers = len(model_bert_encoder.layer)\n",
    "\n",
    "            # we'll always freeze layers bottom up - starting from layers closest to the embeddings\n",
    "            frozen_layers = min(freeze_level, n_encoder_layers)\n",
    "            #\n",
    "            for i in range(frozen_layers):\n",
    "                layer = model_bert_encoder.layer[i]\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -1:\n",
    "            # freeze everything bert\n",
    "            for param in model_bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -2:\n",
    "            # freeze the pooling layer\n",
    "            for param in model_bert_pooler.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -3:\n",
    "            # freeze the embedding layer\n",
    "            for param in model_bert_embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -4:\n",
    "            # freeze the task head\n",
    "            for param in model_tasks.parameters():\n",
    "                param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_dict\n",
    "model_weights_dir = '/projects/home/mmasood1/Model_weights/preclinical_clinical/BERT/'\n",
    "pretrained_model_path = '/projects/home/mmasood1/TG GATE/MolBERT/molbert/molbert_100epochs/molbert_100epochs/checkpoints/last.ckpt'\n",
    "data_dir = '/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/Data_for_BERT_finetuning/'\n",
    "pos_weights = \"/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/06_10_2023/pos_weights.csv\"\n",
    "class_weights = \"/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/06_10_2023/target_weights.csv\"\n",
    "metadata_dir = \"/projects/home/mmasood1/trained_model_predictions/SIDER_PreClinical/BERT_finetune/BERT_MT_BCE_FineTune/\"\n",
    "model_dir = os.path.dirname(os.path.dirname(pretrained_model_path))\n",
    "hparams_path = os.path.join(model_dir, 'hparams.yaml')\n",
    "\n",
    "# load config\n",
    "with open(hparams_path) as yaml_file:\n",
    "    config_dict = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "config_dict['project_name'] = \"BERT_finetuning_MF\"\n",
    "config_dict['model_name'] = \"First_train_head_then_finetune_encoder\"\n",
    "\n",
    "config_dict['model_weights_dir'] = model_weights_dir\n",
    "config_dict['pretrained_model_path'] = pretrained_model_path\n",
    "config_dict[\"metadata_dir\"] = metadata_dir\n",
    "config_dict['pos_weights'] = pos_weights\n",
    "config_dict['class_weights'] = class_weights\n",
    "\n",
    " # architechture\n",
    "config_dict[\"input_dim\"] = 768\n",
    "config_dict[\"hidden_dim\"] = 128\n",
    "config_dict[\"depth\"] = 1\n",
    "config_dict[\"BatchNorm1d\"] = True\n",
    "config_dict[\"use_skip_connection\"] = True\n",
    "config_dict[\"dropout_p\"] = 0.2\n",
    "\n",
    "# Training\n",
    "config_dict['mode'] = 'classification'\n",
    "config_dict['alpha'] = 1.0\n",
    "config_dict['beta'] = 0.0\n",
    "config_dict['epochs'] = 5\n",
    "config_dict['unfreeze_epoch'] = 2\n",
    "config_dict['output_size'] = 50\n",
    "config_dict[\"optim\"] = \"Adam\"\n",
    "config_dict['lr_schedulers'] = \"CosineAnnealingLR\"\n",
    "config_dict['learning_rate'] = 1e-3\n",
    "config_dict[\"BERT_lr\"] = 3e-5\n",
    "config_dict[\"l2_lambda\"] = 1e-2\n",
    "config_dict[\"batch_size\"] = 64\n",
    "\n",
    "config_dict['missing'] = 'nan'\n",
    "config_dict['compute_metric_after_n_epochs'] = 5\n",
    "config_dict['return_trainer'] = True\n",
    "config_dict['EarlyStopping'] = False\n",
    "\n",
    "config_dict[\"accelerator\"] = \"gpu\"\n",
    "config_dict[\"gpu\"] =  [0]\n",
    "config_dict[\"device\"] = torch.device(\"cuda\")\n",
    "config_dict[\"seed\"] = 42\n",
    "\n",
    "config_dict['train_file'] = data_dir + \"complete_training_set.csv\"\n",
    "data = pd.read_csv(config_dict['train_file'])\n",
    "try:\n",
    "    data.drop(['Scafold','fold'], axis = 1, inplace = True)\n",
    "except:\n",
    "    pass\n",
    "target_names = data.loc[:,\"Cytoplasmic alteration (Basophilic/glycogen depletion)\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "\n",
    "#target_names = data.loc[:,\"DILI_binary\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "config_dict[\"label_column\"] = target_names\n",
    "\n",
    "config_dict[\"num_of_tasks\"] = len(target_names)\n",
    "config_dict[\"selected_tasks\"] = target_names\n",
    "config_dict['freeze_level'] = -1\n",
    "config_dict[\"Final_model\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "if config_dict[\"Final_model\"]:\n",
    "    fold_list = [0]\n",
    "else:\n",
    "    fold_list = [0,1,2,3,4]\n",
    "\n",
    "if len(fold_list) == 1:\n",
    "    config_dict['data_dir'] = data_dir\n",
    "    config_dict['train_file'] = data_dir + \"complete_training_set.csv\"\n",
    "    config_dict['valid_file'] = data_dir + \"complete_test_set.csv\"\n",
    "    config_dict['test_file'] = data_dir + \"complete_test_set.csv\"\n",
    "    \n",
    "    train_ids = pd.read_csv(config_dict['train_file']).SMILES.values\n",
    "    val_ids = pd.read_csv(config_dict['valid_file']).SMILES.values\n",
    "    test_ids = pd.read_csv(config_dict['test_file']).SMILES.values\n",
    "else:\n",
    "    fold = 0\n",
    "    config_dict['data_dir'] = data_dir\n",
    "    config_dict['train_file'] = data_dir + f\"train_fold{fold}.csv\"\n",
    "    config_dict['valid_file'] = data_dir + f\"val_fold{fold}.csv\"\n",
    "    config_dict['test_file'] = data_dir + \"complete_test_set.csv\"\n",
    "\n",
    "    train_ids = pd.read_csv(config_dict['train_file']).SMILES.values\n",
    "    val_ids = pd.read_csv(config_dict['valid_file']).SMILES.values\n",
    "    test_ids = pd.read_csv(config_dict['test_file']).SMILES.values\n",
    "\n",
    "featurizer = SmilesIndexFeaturizer.bert_smiles_index_featurizer(config_dict[\"max_seq_length\"], permute = False)\n",
    "train_dataset = BertFinetuneSmilesDataset(\n",
    "            input_path= config_dict['train_file'],\n",
    "            featurizer=featurizer,\n",
    "            single_seq_len=config_dict[\"max_seq_length\"],\n",
    "            total_seq_len=config_dict[\"max_seq_length\"],\n",
    "            label_column=config_dict[\"label_column\"],\n",
    "            is_same=False,\n",
    "            inference_mode=True,\n",
    "        )\n",
    "\n",
    "validation_dataset = BertFinetuneSmilesDataset(\n",
    "            input_path= config_dict['valid_file'],\n",
    "            featurizer=featurizer,\n",
    "            single_seq_len=config_dict[\"max_seq_length\"],\n",
    "            total_seq_len=config_dict[\"max_seq_length\"],\n",
    "            label_column=config_dict[\"label_column\"],\n",
    "            is_same=False,\n",
    "            inference_mode=True,\n",
    "        )\n",
    "\n",
    "test_dataset = BertFinetuneSmilesDataset(\n",
    "            input_path= config_dict['test_file'],\n",
    "            featurizer=featurizer,\n",
    "            single_seq_len=config_dict[\"max_seq_length\"],\n",
    "            total_seq_len=config_dict[\"max_seq_length\"],\n",
    "            label_column=config_dict[\"label_column\"],\n",
    "            is_same=False,\n",
    "            inference_mode=True,\n",
    ")\n",
    "########################################################################\n",
    "train_dataloader = MolbertDataLoader(train_dataset, \n",
    "                                    batch_size=config_dict[\"batch_size\"],\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=4, \n",
    "                                    shuffle = True)\n",
    "\n",
    "validation_dataloader = MolbertDataLoader(validation_dataset, \n",
    "                                    batch_size=config_dict[\"batch_size\"],\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=4, \n",
    "                                    shuffle = False)\n",
    "\n",
    "test_dataloader = MolbertDataLoader(test_dataset, \n",
    "                                    batch_size=config_dict[\"batch_size\"],\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=4, \n",
    "                                    shuffle = False)\n",
    "\n",
    "config_dict[\"num_batches\"] = len(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_init_model(model, \n",
    "                     config, \n",
    "                     train_dataloader,\n",
    "                     val_dataloader, \n",
    "                     model_type):\n",
    "    \n",
    "    default_root_dir = config[\"model_weights_dir\"]\n",
    "    max_epochs = config[\"epochs\"]\n",
    "    return_trainer = config[\"return_trainer\"]\n",
    "\n",
    "    # logger\n",
    "    model = model(config)\n",
    "    wandb_logger = WandbLogger( \n",
    "                        name = config[\"model_name\"],\n",
    "                        save_dir = '/projects/home/mmasood1/Model_weights',\n",
    "                        project= config[\"project_name\"],\n",
    "                        entity=\"arslan_masood\", \n",
    "                        log_model='all',\n",
    "                        )\n",
    "    # trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs= int(max_epochs),\n",
    "        gpus = -1,\n",
    "        logger = wandb_logger,\n",
    "        default_root_dir=default_root_dir)\n",
    "\n",
    "    # model fitting \n",
    "    trainer.fit(model, \n",
    "                train_dataloader = train_dataloader,\n",
    "                val_dataloaders = val_dataloader,\n",
    "                )\n",
    "    if return_trainer:\n",
    "        return model, trainer\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO: GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                   | Type                     | Params\n",
      "--------------------------------------------------------------------\n",
      "0 | weighted_creterien     | BCEWithLogitsLoss        | 0     \n",
      "1 | non_weighted_creterian | BCEWithLogitsLoss        | 0     \n",
      "2 | encoder                | SuperPositionalBertModel | 85 M  \n",
      "3 | input_layer            | Linear                   | 98 K  \n",
      "4 | Hidden_block           | ModuleList               | 16 K  \n",
      "5 | output_layer           | Linear                   | 6 K   \n",
      "6 | dropout                | Dropout                  | 0     \n",
      "7 | batchnorm1             | BatchNorm1d              | 256   \n",
      "INFO: \n",
      "  | Name                   | Type                     | Params\n",
      "--------------------------------------------------------------------\n",
      "0 | weighted_creterien     | BCEWithLogitsLoss        | 0     \n",
      "1 | non_weighted_creterian | BCEWithLogitsLoss        | 0     \n",
      "2 | encoder                | SuperPositionalBertModel | 85 M  \n",
      "3 | input_layer            | Linear                   | 98 K  \n",
      "4 | Hidden_block           | ModuleList               | 16 K  \n",
      "5 | output_layer           | Linear                   | 6 K   \n",
      "6 | dropout                | Dropout                  | 0     \n",
      "7 | batchnorm1             | BatchNorm1d              | 256   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2ec05ba77a42c7a34ee776ccda7610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12b6e93b5ad4cf4ba5bde5f12a70a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 16 batches in order to train on 16 batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ec56acf5d94fadb8a3c064c6e0dd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 4 batches in order to train on 4 batches.\n",
      "INFO: Epoch finished. Accessed 16 batches in order to train on 16 batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ae98bac5cf4a2faa5a94fad41f01f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 4 batches in order to train on 4 batches.\n",
      "INFO: Epoch finished. Accessed 16 batches in order to train on 16 batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c93623acd849beba8b39f431b049b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 4 batches in order to train on 4 batches.\n",
      "INFO: Epoch finished. Accessed 16 batches in order to train on 16 batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85fe2b556f8450c9b0ccc9b80ee69bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 4 batches in order to train on 4 batches.\n",
      "INFO: Epoch finished. Accessed 16 batches in order to train on 16 batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c559a5e7a0c49c3ac2502e8e1fecdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 4 batches in order to train on 4 batches.\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    }
   ],
   "source": [
    "config_dict[\"model_name\"] = rf's{config_dict[\"seed\"]}_alpha_{config_dict[\"alpha\"]}_λ{config_dict[\"l2_lambda\"]}'\n",
    "trained_model, trainer = wandb_init_model(model = MolbertModel, \n",
    "                                            train_dataloader = train_dataloader,\n",
    "                                            val_dataloader =validation_dataloader,\n",
    "                                            config = config_dict, \n",
    "                                            model_type = 'MLP')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config_dict[\"metadata_dir\"] + \"predicitons/\"\n",
    "result_dir = config_dict[\"metadata_dir\"] + \"Results/\"  \n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trained_model.eval()\n",
    "def get_model_predictions_MT(model, selected_dataloader, config, ids):\n",
    "    model = model.cpu() \n",
    "\n",
    "    y_true_list = []\n",
    "    y_pred_list = []\n",
    "\n",
    "    for batch in selected_dataloader:\n",
    "        \n",
    "        (batch_inputs, batch_labels), _ = batch\n",
    "        y = batch_labels[\"finetune\"].squeeze()\n",
    "        y_hat = model(batch_inputs)\n",
    "\n",
    "        y_true_list.append(y.cpu())\n",
    "        y_pred_list.append(y_hat.cpu())\n",
    "\n",
    "    y = torch.cat(y_true_list, dim=0)\n",
    "    y_hat = torch.cat(y_pred_list, dim=0)\n",
    "\n",
    "    if config[\"num_of_tasks\"] > 1:\n",
    "        y = pd.DataFrame(y.cpu().detach().numpy())\n",
    "        y_hat = pd.DataFrame(y_hat.cpu().detach().numpy())\n",
    "        y.columns = config['selected_tasks']\n",
    "        y_hat.columns = config['selected_tasks']\n",
    "    else:\n",
    "        y = pd.DataFrame({config[\"selected_tasks\"]: y.cpu().detach().numpy()})\n",
    "        y_hat = pd.DataFrame({config[\"selected_tasks\"]: y_hat.cpu().detach().numpy().reshape(-1)})\n",
    "        \n",
    "    y.insert(0, \"SMILES\",ids)\n",
    "    y_hat.insert(0, \"SMILES\",ids)\n",
    "    return y, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 4 batches in order to train on 4 batches.\n"
     ]
    }
   ],
   "source": [
    "y, y_hat = get_model_predictions_MT(model, validation_dataloader, config_dict, val_ids)\n",
    "y.to_csv(data_dir + 'y_true_test.csv',index=False)\n",
    "y_hat.to_csv(data_dir + 'y_pred_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################3\n",
    "# Compute compute_binary_classification_metrics: Multitask\n",
    "######################################################################################\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import average_precision_score, f1_score\n",
    "\n",
    "def prob_to_labels(pred, threshold):\n",
    "\t    return (pred >= threshold).astype('int')\n",
    "\n",
    "def compute_binary_classification_metrics_MT(y_true, y_pred_proba, \n",
    "                                             missing):\n",
    "    \"\"\"\n",
    "    Compute various metrics for binary classification.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): Binary labels (0 or 1).\n",
    "        y_pred_proba (array-like): Predictive probabilities for the positive class.\n",
    "        threshold (float, optional): Threshold value for classification. Default is 0.5.\n",
    "    \n",
    "   Returns:\n",
    "        pandas.DataFrame: DataFrame containing the computed metrics for each task (accuracy, ROC AUC, average precision, MCC, F1-score, random precision, gain in average precision).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        num_tasks = y_true.shape[1]  # Get the number of tasks\n",
    "    except:\n",
    "        num_tasks = 1\n",
    "    metrics_list = []\n",
    "\n",
    "    for i in range(num_tasks):\n",
    "        if num_tasks > 1:\n",
    "            y_true_task = y_true[:, i]\n",
    "            y_pred_proba_task = y_pred_proba[:, i]\n",
    "        else:\n",
    "            y_true_task = y_true\n",
    "            y_pred_proba_task = y_pred_proba\n",
    "            \n",
    "        # Apply masking\n",
    "        if missing == 'nan':\n",
    "            mask = ~np.isnan(y_true_task)\n",
    "        if missing == -1:\n",
    "            mask = (y_true_task != -1)\n",
    "\n",
    "        y_true_task = y_true_task[mask]\n",
    "        y_pred_proba_task = y_pred_proba_task[mask]\n",
    "\n",
    "        metrics_task = {}\n",
    "        try:\n",
    "            # ROC AUC\n",
    "            fpr, tpr, th = roc_curve(y_true_task, y_pred_proba_task)\n",
    "            metrics_task['roc_auc'] = auc(fpr, tpr)\n",
    "\n",
    "            # Balanced accuracy\n",
    "            balanced_accuracy = (tpr + (1 - fpr)) / 2\n",
    "            metrics_task['balanced_acc'] = np.max(balanced_accuracy)\n",
    "            \n",
    "            # sensitivity, specificity\n",
    "            optimal_threshold_index = np.argmax(balanced_accuracy)\n",
    "            optimal_threshold = th[optimal_threshold_index]\n",
    "            metrics_task['sensitivity'] = tpr[optimal_threshold_index]\n",
    "            metrics_task['specificity'] = 1 - fpr[optimal_threshold_index]\n",
    "\n",
    "        except:\n",
    "            metrics_task['roc_auc'] = np.nan\n",
    "            metrics_task['sensitivity']= np.nan\n",
    "            metrics_task['specificity']= np.nan\n",
    "        try:\n",
    "            precision, recall, thresholds = precision_recall_curve(y_true_task, y_pred_proba_task)\n",
    "            metrics_task['AUPR'] = auc(recall, precision)\n",
    "            f1 = [f1_score(y_true_task, prob_to_labels(y_pred_proba_task, t)) for t in thresholds]\n",
    "            metrics_task['f1_score'] = np.max(f1)\n",
    "\n",
    "            metrics_task['average_precision'] = average_precision_score(y_true_task, y_pred_proba_task)\n",
    "        except:\n",
    "            metrics_task['AUPR'] = np.nan\n",
    "            metrics_task['f1_score'] = np.nan\n",
    "        \n",
    "\n",
    "        metrics_list.append(metrics_task)\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    col = ['balanced_acc', 'f1_score','specificity','sensitivity', 'roc_auc','AUPR', 'average_precision']\n",
    "    \n",
    "    return metrics_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "data = pd.read_csv(config_dict[\"data_dir\"] + \"train_fold0.csv\")\n",
    "target_names = data.loc[:,\"Cytoplasmic alteration (Basophilic/glycogen depletion)\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "#target_names = data.loc[:,\"DILI_binary\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "config[\"num_of_tasks\"] = len(target_names)\n",
    "config[\"selected_tasks\"] = target_names\n",
    "\n",
    "preclinical_tasks = config[\"selected_tasks\"][:20]\n",
    "clinical_tasks = config[\"selected_tasks\"][20:]\n",
    "\n",
    "pathological_tasks = ['Cytoplasmic alteration (Basophilic/glycogen depletion)',\n",
    "                        'Cytoplasmic alteration (Eosinophilic)',\n",
    "                        'Extramedullary Hematopoiesis',\n",
    "                        'Hypertrophy, hepatocellular',\n",
    "                        'Hypertrophy/Hyperplasia',\n",
    "                        'Increased mitoses',\n",
    "                        'Infiltration, Mononuclear',\n",
    "                        'Necrosis',\n",
    "                        'Pigmentation (pigment deposition)',\n",
    "                        'Single Cell Necrosis',\n",
    "                        'Vacuolation',\n",
    "                        'DILI_binary']\n",
    "\n",
    "blood_tasks = ['ALP(IU/L)',\n",
    "                'AST(IU/L)',\n",
    "                'ALT(IU/L)',\n",
    "                'GTP(IU/L)',\n",
    "                'TC(mg/dL)',\n",
    "                'TG(mg/dL)',\n",
    "                'TBIL(mg/dL)',\n",
    "                'DBIL(mg/dL)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_binary_classification_metrics_MT(y_true = y[config['selected_tasks']].values, \n",
    "                                                    y_pred_proba = y_hat[config['selected_tasks']].values,\n",
    "                                                                        missing = 'nan')\n",
    "metrics.insert(0, 'Tasks', target_names)\n",
    "mean_preformances = {\"pathology_mean\": metrics[metrics.Tasks.isin(pathological_tasks)].iloc[:,1:].mean(),\n",
    "                    \"blood_mean\": metrics[metrics.Tasks.isin(blood_tasks)].iloc[:,1:].mean(),\n",
    "                    \"preclinical_mean\": metrics[metrics.Tasks.isin(preclinical_tasks)].iloc[:,1:].mean(),\n",
    "                    \"clinical_mean\": metrics[metrics.Tasks.isin(clinical_tasks)].iloc[:,1:].mean(),\n",
    "                    \"combined_ex_BM\":metrics[metrics.Tasks.isin(clinical_tasks + pathological_tasks)].iloc[:,1:].mean(),\n",
    "                    \"combined_all\": metrics.iloc[:,1:].mean()}\n",
    "mean_preformances = pd.DataFrame(mean_preformances).T\n",
    "mean_preformances = mean_preformances.rename_axis('Tasks').reset_index()\n",
    "metrics = pd.concat([metrics, mean_preformances], ignore_index=True) \n",
    "metrics.to_csv(result_dir + f'val_metric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tasks</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>blood_mean</td>\n",
       "      <td>0.769882</td>\n",
       "      <td>0.304288</td>\n",
       "      <td>0.668931</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>0.740225</td>\n",
       "      <td>0.180937</td>\n",
       "      <td>0.211814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>preclinical_mean</td>\n",
       "      <td>0.762112</td>\n",
       "      <td>0.278317</td>\n",
       "      <td>0.662165</td>\n",
       "      <td>0.862060</td>\n",
       "      <td>0.707930</td>\n",
       "      <td>0.156609</td>\n",
       "      <td>0.189075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>clinical_mean</td>\n",
       "      <td>0.622902</td>\n",
       "      <td>0.334131</td>\n",
       "      <td>0.577154</td>\n",
       "      <td>0.668649</td>\n",
       "      <td>0.591154</td>\n",
       "      <td>0.221321</td>\n",
       "      <td>0.233160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>combined_ex_BM</td>\n",
       "      <td>0.661196</td>\n",
       "      <td>0.313237</td>\n",
       "      <td>0.600154</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.618367</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.216233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>combined_all</td>\n",
       "      <td>0.678586</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.611158</td>\n",
       "      <td>0.746013</td>\n",
       "      <td>0.637864</td>\n",
       "      <td>0.195436</td>\n",
       "      <td>0.215526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tasks  balanced_acc  f1_score  specificity  sensitivity  \\\n",
       "51        blood_mean      0.769882  0.304288     0.668931     0.870833   \n",
       "52  preclinical_mean      0.762112  0.278317     0.662165     0.862060   \n",
       "53     clinical_mean      0.622902  0.334131     0.577154     0.668649   \n",
       "54    combined_ex_BM      0.661196  0.313237     0.600154     0.722238   \n",
       "55      combined_all      0.678586  0.311805     0.611158     0.746013   \n",
       "\n",
       "     roc_auc      AUPR  average_precision  \n",
       "51  0.740225  0.180937           0.211814  \n",
       "52  0.707930  0.156609           0.189075  \n",
       "53  0.591154  0.221321           0.233160  \n",
       "54  0.618367  0.198198           0.216233  \n",
       "55  0.637864  0.195436           0.215526  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
