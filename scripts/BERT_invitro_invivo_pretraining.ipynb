{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmasood1/.conda/envs/molbert/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "import gc\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import os, yaml\n",
    "from argparse import Namespace\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "from sklearn.metrics import average_precision_score, f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "\n",
    "\n",
    "import wandb\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "wandb.login(key = \"27edf9c66b032c03f72d30e923276b93aa736429\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from molbert.models.smiles import SmilesMolbertModel\n",
    "from molbert.datasets.dataloading import CombinedMolbertDataLoader_cyclic, CombinedMolbertDataLoader_max, get_dataloaders\n",
    "from molbert.utils.featurizer.molfeaturizer import SmilesIndexFeaturizer\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, StepLR\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_constant_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# config_dict\n",
    "model_weights_dir = '/projects/home/mmasood1/Model_weights/invitro/invitro_1million/MolBERT/Retrain_on_top_of_BERT/complete_1m_300k_ADME/ADME_masking_invitro_physchem_init_pretrained/'\n",
    "pretrained_model_path = '/projects/home/mmasood1/TG GATE/MolBERT/molbert/molbert_100epochs/molbert_100epochs/checkpoints/last.ckpt'\n",
    "data_dir = '/projects/home/mmasood1/arslan_data_repository/invitro/invitro_1m/25_04_2024/SMILES_len_th_128/'\n",
    "pos_weights = \"/projects/home/mmasood1/arslan_data_repository/invitro/invitro_1m/25_04_2024/pos_weights.csv\"\n",
    "metadata_dir = \"/projects/home/mmasood1/trained_model_predictions/SIDER_PreClinical/BERT_finetune/MF/\"\n",
    "model_dir = os.path.dirname(os.path.dirname(pretrained_model_path))\n",
    "hparams_path = os.path.join(model_dir, 'hparams.yaml')\n",
    "# load config\n",
    "with open(hparams_path) as yaml_file:\n",
    "    config_dict = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "config_dict['project_name'] = \"BERT_invitro_ADME_pretraining\"\n",
    "config_dict['model_name'] = \"ADME_masking_invitro_physchem_init_pretrained\"\n",
    "\n",
    "config_dict['model_weights_dir'] = model_weights_dir\n",
    "config_dict['pretrained_model_path'] = pretrained_model_path\n",
    "config_dict[\"metadata_dir\"] = metadata_dir\n",
    "config_dict['pos_weights'] = pos_weights\n",
    "config_dict['data_dir'] = data_dir\n",
    "config_dict['invitro_train'] = data_dir + \"train_set_invitro_1m_300k_ADME_filtered.pkl\"\n",
    "config_dict['invitro_val'] = data_dir + \"test_set_invitro_1m_300k_ADME_filtered.pkl\"\n",
    "config_dict['invitro_test'] = data_dir + \"test_set_invitro_1m_300k_ADME_filtered.pkl\"\n",
    "\n",
    "config_dict['mode'] = 'classification'\n",
    "config_dict['alpha'] = 0.0\n",
    "config_dict['beta'] = 0.0\n",
    "config_dict['gamma'] = 0.0\n",
    "\n",
    "config_dict['max_epochs'] = 20\n",
    "config_dict['unfreeze_epoch'] = 210\n",
    "config_dict[\"l2_lambda\"] = 0.0\n",
    "config_dict['embedding_size'] = 50\n",
    "config_dict[\"num_physchem_properties\"] = 200\n",
    "\n",
    "config_dict['optim'] = 'AdamW'#SGD\n",
    "config_dict['loss_type'] = 'BCE'# Focal_loss\n",
    "\n",
    "config_dict['lr'] = 1e-05\n",
    "config_dict[\"BERT_lr\"] = 3e-5\n",
    "config_dict[\"invitro_batch_size\"] = 128\n",
    "config_dict[\"invivo_batch_size\"] = 64\n",
    "\n",
    "config_dict[\"seed\"] = 42\n",
    "\n",
    "\n",
    "\n",
    "config_dict['missing'] = 'nan'\n",
    "config_dict['compute_metric_after_n_epochs'] = 5\n",
    "config_dict['return_trainer'] = True\n",
    "config_dict['EarlyStopping'] = False\n",
    "\n",
    "config_dict[\"accelerator\"] = \"gpu\"\n",
    "config_dict[\"device\"] = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "data = pd.read_pickle(config_dict['invitro_train'])\n",
    "data.drop(['SMILES'], axis = 1, inplace = True)\n",
    "target_names = data.columns.tolist()\n",
    "\n",
    "config_dict[\"output_size\"] = len(target_names)\n",
    "config_dict[\"num_invitro_tasks\"] = len(target_names)\n",
    "config_dict[\"num_of_tasks\"] = len(target_names)\n",
    "\n",
    "config_dict[\"invitro_columns\"] = target_names\n",
    "config_dict['num_mols'] = data.shape[0]\n",
    "config_dict['max_seq_length'] = 128\n",
    "config_dict['bert_output_dim'] = 768\n",
    "config_dict['invitro_head_hidden_layer'] = 2048\n",
    "\n",
    "############## invivo ###########################\n",
    "config_dict[\"invivo_train\"] = \"/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/Data_for_BERT_finetuning/complete_training_set.csv\"\n",
    "config_dict[\"invivo_val\"] = \"/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/Data_for_BERT_finetuning/complete_test_set.csv\"\n",
    "\n",
    "data = pd.read_csv(config_dict['invivo_train'])\n",
    "data.drop(['SMILES','Scafold','fold'], axis = 1, inplace = True)\n",
    "invivo_target_names = data.columns.tolist()\n",
    "config_dict[\"num_invivo_tasks\"] = len(invivo_target_names)\n",
    "config_dict[\"invivo_columns\"] = invivo_target_names\n",
    "###############################################\n",
    "config_dict[\"permute\"] = False\n",
    "\n",
    "config_dict['pretrained_model'] = True\n",
    "config_dict['freeze_level'] = False\n",
    "config_dict[\"gpu\"] = -1\n",
    "config_dict[\"precision\"] = 32\n",
    "config_dict[\"distributed_backend\"] = \"dp\"\n",
    "config_dict[\"pretrained_crash_model\"] = \"/projects/home/mmasood1/Model_weights/invitro/invitro_1million/MolBERT/Retrain_on_top_of_BERT/complete_1m_300k_ADME/ADME_masking_invitro_physchem_init_pretrained/epoch=0-step=0.ckpt\"\n",
    "\n",
    "featurizer = SmilesIndexFeaturizer.bert_smiles_index_featurizer(config_dict[\"max_seq_length\"], permute = False)\n",
    "#elements = featurizer.load_periodic_table()[0]\n",
    "#featurizer = SmilesIndexFeaturizer.bert_smiles_index_featurizer(max_length=config_dict[\"max_seq_length\"], \n",
    "#                                                                allowed_elements=tuple(elements),\n",
    "#                                                                permute = False)\n",
    "config_dict[\"vocab_size\"] = featurizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1235, 1.2346, 2.3457])\n",
      "tensor([0.1235, 1.2344, 2.3457], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example predictions as float32\n",
    "predictions_float32 = torch.tensor([0.123456789, 1.23456789, 2.3456789], dtype=torch.float32)\n",
    "\n",
    "# Convert predictions to float16\n",
    "predictions_float16 = predictions_float32.to(torch.float16)\n",
    "\n",
    "print(predictions_float32)\n",
    "print(predictions_float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "invitro_train_dataloader_clean, invitro_train_dataloader_corrupted = get_dataloaders(\n",
    "                                                                    datafile = config_dict['invitro_train'],\n",
    "                                                                    featurizer = featurizer,\n",
    "                                                                    targets = \"invitro\", \n",
    "                                                                    batch_size = config_dict[\"invitro_batch_size\"], \n",
    "                                                                    num_workers = 16, shuffle = False,\n",
    "                                                                    config_dict = config_dict)\n",
    "\n",
    "invivo_train_dataloader_clean, invivo_train_dataloader_corrupted = get_dataloaders(\n",
    "                                                                    datafile = config_dict['invivo_train'], \n",
    "                                                                    featurizer = featurizer,\n",
    "                                                                    targets = \"invivo\", \n",
    "                                                                    batch_size = config_dict[\"invivo_batch_size\"], \n",
    "                                                                    num_workers = 16, shuffle = False,\n",
    "                                                                    config_dict = config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corrupted_cleaned_data(batch):\n",
    "        invitro_clean, invivo_clean, invitro_masked, invivo_masked = batch[0], batch[1], batch[2], batch[3]\n",
    "        (invitro_clean_inputs, _), _ = invitro_clean\n",
    "        (invivo_clean_inputs, _), _ = invivo_clean\n",
    "\n",
    "        (invitro_masked_inputs, invitro_masked_labels), _ = invitro_masked\n",
    "        (invivo_masked_inputs, invivo_masked_labels), _ = invivo_masked\n",
    "\n",
    "        if invivo_masked_inputs is not None:\n",
    "            # two sets of inputs (each with invitro and invivo molecules)\n",
    "            batch_inputs_clean = {k: torch.cat([invitro_clean_inputs[k], invivo_clean_inputs[k]], dim=0) for k in invitro_clean_inputs.keys()}\n",
    "            batch_inputs_corrupted = {k: torch.cat([invitro_masked_inputs[k], invivo_masked_inputs[k]], dim=0) for k in invitro_masked_inputs.keys()}\n",
    "\n",
    "            # concatenate batch outputs (only consider masked labels)\n",
    "            invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "            invivo_labels = invivo_masked_labels[\"invitro\"].squeeze()\n",
    "\n",
    "            missing_invitro_labels = torch.full((invivo_labels.shape[0], 1234), -1)\n",
    "            missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "            batch_labels = {\"lm_label_ids\":torch.cat([invitro_masked_labels[\"lm_label_ids\"], invivo_masked_labels[\"lm_label_ids\"]], dim=0),\n",
    "                            \"unmasked_lm_label_ids\":torch.cat([invitro_masked_labels[\"unmasked_lm_label_ids\"], invivo_masked_labels[\"unmasked_lm_label_ids\"]], dim=0),\n",
    "                            \"physchem_props\":torch.cat([invitro_masked_labels[\"physchem_props\"], invivo_masked_labels[\"physchem_props\"]], dim=0),\n",
    "                            \"invitro\":torch.cat([invitro_labels, missing_invitro_labels], dim=0),\n",
    "                            \"invivo\":torch.cat([missing_invivo_labels, invivo_labels], dim=0),\n",
    "                            }\n",
    "        else:\n",
    "            batch_inputs_clean = invitro_clean_inputs\n",
    "            batch_inputs_corrupted = invitro_masked_inputs\n",
    "\n",
    "            invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "            missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "            batch_labels = invitro_masked_labels\n",
    "            batch_labels[\"invitro\"] = invitro_labels\n",
    "            batch_labels[\"invivo\"] = missing_invivo_labels\n",
    "        \n",
    "        return batch_inputs_clean, batch_inputs_corrupted, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = CombinedMolbertDataLoader_cyclic(\n",
    "                                             invitro_train_dataloader_clean, \n",
    "                                             invivo_train_dataloader_clean,\n",
    "                                             invitro_train_dataloader_corrupted,\n",
    "                                             invivo_train_dataloader_corrupted\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "1\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "2\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "3\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "4\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "5\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "6\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "7\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "8\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "9\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "10\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "11\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "12\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "13\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "14\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "15\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "16\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "17\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "18\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "19\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "20\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "21\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "22\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "23\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "24\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "25\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "26\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "27\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "28\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "29\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "30\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "31\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "32\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "33\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "34\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "35\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "36\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "37\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "38\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "39\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "40\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "41\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "42\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "43\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "44\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "45\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "46\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "47\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "48\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "49\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "50\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "51\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "52\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "53\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "54\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "55\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "56\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "57\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "58\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "59\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "60\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "61\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "62\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "63\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "64\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "65\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "66\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "67\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "68\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "69\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "70\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "71\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "72\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "73\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "74\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "75\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "76\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "77\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "78\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "79\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "80\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "81\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "82\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "83\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "84\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "85\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "86\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "87\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "88\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "89\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "90\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "91\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "92\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "93\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "94\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "95\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "96\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "97\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "98\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "99\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "100\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "101\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "102\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "103\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "104\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "105\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "106\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "107\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "108\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "109\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "110\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "111\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26337/898464874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_inputs_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_inputs_corrupted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_corrupted_cleaned_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/home/mmasood1/TG GATE/MolBERT/molbert/datasets/dataloading.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mbatch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mbatch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mbatch3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/molbert/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_count = 0\n",
    "for batch in train_dataloader:\n",
    "    batch_inputs_clean, batch_inputs_corrupted, batch_labels = extract_corrupted_cleaned_data(batch)\n",
    "    batch_count = batch_count + 1\n",
    "    print(batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(invitro_train_dataloader_clean))\n",
    "(batch_inputs1, batch_labels1), valids1 = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[ 1,  8,  9,  ...,  0,  0,  0],\n",
       "          [ 1,  9,  8,  ...,  0,  0,  0],\n",
       "          [ 1, 10,  8,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 1,  8, 10,  ...,  0,  0,  0],\n",
       "          [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "          [ 1, 10, 29,  ...,  0,  0,  0]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " {'lm_label_ids': tensor([[-1, -1, -1,  ..., -1, -1, -1],\n",
       "          [-1, -1, -1,  ..., -1, -1, -1],\n",
       "          [-1, -1, -1,  ..., -1, -1, -1],\n",
       "          ...,\n",
       "          [-1, -1, -1,  ..., -1, -1, -1],\n",
       "          [-1, -1, -1,  ..., -1, -1, -1],\n",
       "          [-1, -1, -1,  ..., -1, -1, -1]]),\n",
       "  'unmasked_lm_label_ids': tensor([[ 1,  8,  9,  ...,  0,  0,  0],\n",
       "          [ 1,  9,  8,  ...,  0,  0,  0],\n",
       "          [ 1, 10,  8,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 1,  8, 10,  ...,  0,  0,  0],\n",
       "          [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "          [ 1, 10, 29,  ...,  0,  0,  0]]),\n",
       "  'physchem_props': tensor([[9.0465e-01, 1.1381e-02, 1.3623e-02,  ..., 1.6466e-01, 2.8392e-16,\n",
       "           7.1686e-01],\n",
       "          [4.9763e-01, 6.4444e-02, 4.7372e-02,  ..., 9.9571e-01, 2.8392e-16,\n",
       "           5.8116e-01],\n",
       "          [9.7572e-01, 1.0608e-03, 1.1928e-03,  ..., 1.6466e-01, 2.8392e-16,\n",
       "           2.2379e-01],\n",
       "          ...,\n",
       "          [8.2223e-01, 4.1672e-01, 4.9491e-01,  ..., 1.6466e-01, 2.8392e-16,\n",
       "           3.9210e-01],\n",
       "          [7.2781e-02, 1.3974e-02, 1.6103e-01,  ..., 1.0000e+00, 2.8392e-16,\n",
       "           1.8840e-01],\n",
       "          [8.3458e-01, 1.1230e-01, 1.5790e-01,  ..., 1.6466e-01, 2.8392e-16,\n",
       "           5.5683e-01]]),\n",
       "  'invitro': tensor([[[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "  \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "  \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "  \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "  \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.]]])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invitro_train_dataloader_clean.trim_batch(batch_inputs1, batch_labels1, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1,  8,  9,  ...,  0,  0,  0],\n",
       "         [ 1,  9,  8,  ...,  0,  0,  0],\n",
       "         [ 1, 10,  8,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 1,  8, 10,  ...,  0,  0,  0],\n",
       "         [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "         [ 1, 10, 29,  ...,  0,  0,  0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_inputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8870"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "invitro_clean, invivo_clean, invitro_masked, invivo_masked = batch[0], batch[1], batch[2], batch[3]\n",
    "\n",
    "(invitro_clean_inputs, _), _ = invitro_clean\n",
    "(invivo_clean_inputs, _), _ = invivo_clean\n",
    "\n",
    "(invitro_masked_inputs, invitro_masked_labels), _ = invitro_masked\n",
    "(invivo_masked_inputs, invivo_masked_labels), _ = invivo_masked\n",
    "\n",
    "# two sets of inputs (each with invitro and invivo molecules)\n",
    "batch_inputs_clean = {k: torch.cat([invitro_clean_inputs[k], invivo_clean_inputs[k]], dim=0) for k in invitro_clean_inputs.keys()}\n",
    "batch_inputs_corrupted = {k: torch.cat([invitro_masked_inputs[k], invivo_masked_inputs[k]], dim=0) for k in invitro_masked_inputs.keys()}\n",
    "\n",
    "# As we are concatenating inputs (invitro + invivo)\n",
    "# Model will predict output of all molecules (invitro + invivo)\n",
    "# Concatnate missing labels with -1 to the available labels\n",
    "\n",
    "invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "invivo_labels = invivo_masked_labels[\"invitro\"].squeeze()\n",
    "\n",
    "missing_invitro_labels = torch.full((invivo_labels.shape[0], 1234), -1)\n",
    "missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "batch_labels = {\"lm_label_ids\":torch.cat([invitro_masked_labels[\"lm_label_ids\"], invivo_masked_labels[\"lm_label_ids\"]], dim=0),\n",
    "                \"unmasked_lm_label_ids\":torch.cat([invitro_masked_labels[\"unmasked_lm_label_ids\"], invivo_masked_labels[\"unmasked_lm_label_ids\"]], dim=0),\n",
    "                \"physchem_props\":torch.cat([invitro_masked_labels[\"physchem_props\"], invivo_masked_labels[\"physchem_props\"]], dim=0),\n",
    "                \"invitro\":torch.cat([invitro_labels, missing_invitro_labels], dim=0),\n",
    "                \"invivo\":torch.cat([missing_invivo_labels, invivo_labels], dim=0),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corrupted_cleaned_data(batch):\n",
    "        invitro_clean, invivo_clean, invitro_masked, invivo_masked = batch[0], batch[1], batch[2], batch[3]\n",
    "        (invitro_clean_inputs, _), _ = invitro_clean\n",
    "        (invivo_clean_inputs, _), _ = invivo_clean\n",
    "\n",
    "        (invitro_masked_inputs, invitro_masked_labels), _ = invitro_masked\n",
    "        (invivo_masked_inputs, invivo_masked_labels), _ = invivo_masked\n",
    "\n",
    "        if invivo_masked_inputs is not None:\n",
    "            # two sets of inputs (each with invitro and invivo molecules)\n",
    "            batch_inputs_clean = {k: torch.cat([invitro_clean_inputs[k], invivo_clean_inputs[k]], dim=0) for k in invitro_clean_inputs.keys()}\n",
    "            batch_inputs_corrupted = {k: torch.cat([invitro_masked_inputs[k], invivo_masked_inputs[k]], dim=0) for k in invitro_masked_inputs.keys()}\n",
    "\n",
    "            # concatenate batch outputs (only consider masked labels)\n",
    "            invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "            invivo_labels = invivo_masked_labels[\"invitro\"].squeeze()\n",
    "\n",
    "            missing_invitro_labels = torch.full((invivo_labels.shape[0], 1234), -1)\n",
    "            missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "            batch_labels = {\"lm_label_ids\":torch.cat([invitro_masked_labels[\"lm_label_ids\"], invivo_masked_labels[\"lm_label_ids\"]], dim=0),\n",
    "                            \"unmasked_lm_label_ids\":torch.cat([invitro_masked_labels[\"unmasked_lm_label_ids\"], invivo_masked_labels[\"unmasked_lm_label_ids\"]], dim=0),\n",
    "                            \"physchem_props\":torch.cat([invitro_masked_labels[\"physchem_props\"], invivo_masked_labels[\"physchem_props\"]], dim=0),\n",
    "                            \"invitro\":torch.cat([invitro_labels, missing_invitro_labels], dim=0),\n",
    "                            \"invivo\":torch.cat([missing_invivo_labels, invivo_labels], dim=0),\n",
    "                            }\n",
    "        else:\n",
    "            batch_inputs_clean = invitro_clean_inputs\n",
    "            batch_inputs_corrupted = invitro_masked_inputs\n",
    "\n",
    "            invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "            missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "            batch_labels = invitro_masked_labels\n",
    "            batch_labels[\"invitro\"] = invitro_labels\n",
    "            batch_labels[\"invivo\"] = missing_invivo_labels\n",
    "        \n",
    "        return batch_inputs_clean, batch_inputs_corrupted, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 77 114 77 114\n",
      "max_idx 114\n",
      "invitro_trim torch.Size([128, 114]) torch.Size([128, 114])\n",
      "invivo_trim  torch.Size([64, 114]) torch.Size([64, 114])\n",
      "1\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 84 117 84 117\n",
      "max_idx 117\n",
      "invitro_trim torch.Size([128, 117]) torch.Size([128, 117])\n",
      "invivo_trim  torch.Size([64, 117]) torch.Size([64, 117])\n",
      "2\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 63 101 63 101\n",
      "max_idx 101\n",
      "invitro_trim torch.Size([128, 101]) torch.Size([128, 101])\n",
      "invivo_trim  torch.Size([64, 101]) torch.Size([64, 101])\n",
      "3\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 99 114 99 114\n",
      "max_idx 114\n",
      "invitro_trim torch.Size([128, 114]) torch.Size([128, 114])\n",
      "invivo_trim  torch.Size([64, 114]) torch.Size([64, 114])\n",
      "4\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 68 65 68 65\n",
      "max_idx 68\n",
      "invitro_trim torch.Size([128, 68]) torch.Size([128, 68])\n",
      "invivo_trim  torch.Size([64, 68]) torch.Size([64, 68])\n",
      "5\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 66 99 66 99\n",
      "max_idx 99\n",
      "invitro_trim torch.Size([128, 99]) torch.Size([128, 99])\n",
      "invivo_trim  torch.Size([64, 99]) torch.Size([64, 99])\n",
      "6\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 97 120 97 120\n",
      "max_idx 120\n",
      "invitro_trim torch.Size([128, 120]) torch.Size([128, 120])\n",
      "invivo_trim  torch.Size([64, 120]) torch.Size([64, 120])\n",
      "7\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 97 85 97 85\n",
      "max_idx 97\n",
      "invitro_trim torch.Size([128, 97]) torch.Size([128, 97])\n",
      "invivo_trim  torch.Size([64, 97]) torch.Size([64, 97])\n",
      "8\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 70 126 70 126\n",
      "max_idx 126\n",
      "invitro_trim torch.Size([128, 126]) torch.Size([128, 126])\n",
      "invivo_trim  torch.Size([64, 126]) torch.Size([64, 126])\n",
      "9\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 80 120 80 120\n",
      "max_idx 120\n",
      "invitro_trim torch.Size([128, 120]) torch.Size([128, 120])\n",
      "invivo_trim  torch.Size([64, 120]) torch.Size([64, 120])\n",
      "10\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 79 120 79 120\n",
      "max_idx 120\n",
      "invitro_trim torch.Size([128, 120]) torch.Size([128, 120])\n",
      "invivo_trim  torch.Size([64, 120]) torch.Size([64, 120])\n",
      "11\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 86 117 86 117\n",
      "max_idx 117\n",
      "invitro_trim torch.Size([128, 117]) torch.Size([128, 117])\n",
      "invivo_trim  torch.Size([64, 117]) torch.Size([64, 117])\n",
      "12\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 70 123 70 123\n",
      "max_idx 123\n",
      "invitro_trim torch.Size([128, 123]) torch.Size([128, 123])\n",
      "invivo_trim  torch.Size([64, 123]) torch.Size([64, 123])\n",
      "13\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 94 103 94 103\n",
      "max_idx 103\n",
      "invitro_trim torch.Size([128, 103]) torch.Size([128, 103])\n",
      "invivo_trim  torch.Size([64, 103]) torch.Size([64, 103])\n",
      "14\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 90 99 90 99\n",
      "max_idx 99\n",
      "invitro_trim torch.Size([128, 99]) torch.Size([128, 99])\n",
      "invivo_trim  torch.Size([64, 99]) torch.Size([64, 99])\n",
      "15\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 97 122 97 122\n",
      "max_idx 122\n",
      "invitro_trim torch.Size([128, 122]) torch.Size([128, 122])\n",
      "invivo_trim  torch.Size([64, 122]) torch.Size([64, 122])\n",
      "16\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 87 86 87 86\n",
      "max_idx 87\n",
      "invitro_trim torch.Size([128, 87]) torch.Size([128, 87])\n",
      "invivo_trim  torch.Size([64, 87]) torch.Size([64, 87])\n",
      "17\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 90 118 90 118\n",
      "max_idx 118\n",
      "invitro_trim torch.Size([128, 118]) torch.Size([128, 118])\n",
      "invivo_trim  torch.Size([64, 118]) torch.Size([64, 118])\n",
      "18\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 128]) torch.Size([64, 128])\n",
      "all max 88 123 88 123\n",
      "max_idx 123\n",
      "invitro_trim torch.Size([128, 123]) torch.Size([128, 123])\n",
      "invivo_trim  torch.Size([64, 123]) torch.Size([64, 123])\n",
      "19\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 114]) torch.Size([64, 114])\n",
      "all max 94 114 94 114\n",
      "max_idx 114\n",
      "invitro_trim torch.Size([128, 114]) torch.Size([128, 114])\n",
      "invivo_trim  torch.Size([64, 114]) torch.Size([64, 114])\n",
      "20\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 117]) torch.Size([64, 117])\n",
      "all max 101 117 101 117\n",
      "max_idx 117\n",
      "invitro_trim torch.Size([128, 117]) torch.Size([128, 117])\n",
      "invivo_trim  torch.Size([64, 117]) torch.Size([64, 117])\n",
      "21\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 101]) torch.Size([64, 101])\n",
      "all max 93 101 93 101\n",
      "max_idx 101\n",
      "invitro_trim torch.Size([128, 101]) torch.Size([128, 101])\n",
      "invivo_trim  torch.Size([64, 101]) torch.Size([64, 101])\n",
      "22\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 114]) torch.Size([64, 114])\n",
      "all max 105 114 105 114\n",
      "max_idx 114\n",
      "invitro_trim torch.Size([128, 114]) torch.Size([128, 114])\n",
      "invivo_trim  torch.Size([64, 114]) torch.Size([64, 114])\n",
      "23\n",
      "invitro torch.Size([128, 128]) torch.Size([128, 128])\n",
      "invivo torch.Size([64, 68]) torch.Size([64, 68])\n",
      "all max 84 65 84 65\n",
      "max_idx 84\n",
      "invitro_trim torch.Size([128, 84]) torch.Size([128, 84])\n",
      "invivo_trim  torch.Size([64, 68]) torch.Size([64, 68])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 84 and 68 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82851/898464874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbatch_inputs_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_inputs_corrupted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_corrupted_cleaned_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_82851/2249696221.py\u001b[0m in \u001b[0;36mextract_corrupted_cleaned_data\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minvivo_masked_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# two sets of inputs (each with invitro and invivo molecules)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mbatch_inputs_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_inputs_corrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_82851/2249696221.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minvivo_masked_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# two sets of inputs (each with invitro and invivo molecules)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mbatch_inputs_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_inputs_corrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 84 and 68 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "batch_count = 0\n",
    "for batch in train_dataloader:\n",
    "    batch_inputs_clean, batch_inputs_corrupted, batch_labels = extract_corrupted_cleaned_data(batch)\n",
    "    batch_count = batch_count + 1\n",
    "    print(batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 105 and 101 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48627/3713590907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# two sets of inputs (each with invitro and invivo molecules)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mbatch_inputs_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_inputs_corrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48627/3713590907.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# two sets of inputs (each with invitro and invivo molecules)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mbatch_inputs_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_clean_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_clean_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_inputs_corrupted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvivo_masked_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvitro_masked_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 105 and 101 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "invitro_clean, invivo_clean, invitro_masked, invivo_masked = batch[0], batch[1], batch[2], batch[3]\n",
    "(invitro_clean_inputs, _), _ = invitro_clean\n",
    "(invivo_clean_inputs, _), _ = invivo_clean\n",
    "\n",
    "(invitro_masked_inputs, invitro_masked_labels), _ = invitro_masked\n",
    "(invivo_masked_inputs, invivo_masked_labels), _ = invivo_masked\n",
    "\n",
    "if invivo_masked_inputs is not None:\n",
    "    # two sets of inputs (each with invitro and invivo molecules)\n",
    "   \n",
    "    batch_inputs_clean = {k: torch.cat([invitro_clean_inputs[k], invivo_clean_inputs[k]], dim=0) for k in invitro_clean_inputs.keys()}\n",
    "    batch_inputs_corrupted = {k: torch.cat([invitro_masked_inputs[k], invivo_masked_inputs[k]], dim=0) for k in invitro_masked_inputs.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 105]), torch.Size([64, 101]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invitro_clean_inputs[\"input_ids\"].shape,  invivo_clean_inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 101])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invivo_clean_inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([26, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch in invivo_train_dataloader_clean:\n",
    "    (inputs, labels), _ = batch\n",
    "    print(inputs[\"attention_mask\"].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48627/1242080219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val dataloaders\n",
    "invitro_val_dataloader_clean, invitro_val_dataloader_corrupted = get_dataloaders(\n",
    "                                                                    datafile = config_dict['invitro_val'],\n",
    "                                                                    featurizer = featurizer,\n",
    "                                                                    targets = \"invitro\", \n",
    "                                                                    batch_size = config_dict[\"invitro_batch_size\"], \n",
    "                                                                    num_workers = 4, shuffle = False,\n",
    "                                                                    config_dict = config_dict)\n",
    "\n",
    "invivo_val_dataloader_clean, invivo_val_dataloader_corrupted = get_dataloaders(\n",
    "                                                                    datafile = config_dict['invivo_val'], \n",
    "                                                                    featurizer = featurizer,\n",
    "                                                                    targets = \"invivo\", \n",
    "                                                                    batch_size = config_dict[\"invivo_batch_size\"], \n",
    "                                                                    num_workers = 4, shuffle = False,\n",
    "                                                                    config_dict = config_dict)\n",
    "val_dataloader = CombinedMolbertDataLoader_max(\n",
    "                                             invitro_val_dataloader_clean, \n",
    "                                             invivo_val_dataloader_clean,\n",
    "                                             invitro_val_dataloader_corrupted,\n",
    "                                             invivo_val_dataloader_corrupted\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "invitro_clean, invivo_clean, invitro_masked, invivo_masked = batch[0], batch[1], batch[2], batch[3]\n",
    "\n",
    "(invitro_clean_inputs, _), _ = invitro_clean\n",
    "(invivo_clean_inputs, _), _ = invivo_clean\n",
    "\n",
    "(invitro_masked_inputs, invitro_masked_labels), _ = invitro_masked\n",
    "(invivo_masked_inputs, invivo_masked_labels), _ = invivo_masked\n",
    "\n",
    "# two sets of inputs (each with invitro and invivo molecules)\n",
    "batch_inputs_clean = {k: torch.cat([invitro_clean_inputs[k], invivo_clean_inputs[k]], dim=0) for k in invitro_clean_inputs.keys()}\n",
    "batch_inputs_corrupted = {k: torch.cat([invitro_masked_inputs[k], invivo_masked_inputs[k]], dim=0) for k in invitro_masked_inputs.keys()}\n",
    "\n",
    "# As we are concatenating inputs (invitro + invivo)\n",
    "# Model will predict output of all molecules (invitro + invivo)\n",
    "# Concatnate missing labels with -1 to the available labels\n",
    "\n",
    "invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "invivo_labels = invivo_masked_labels[\"invitro\"].squeeze()\n",
    "\n",
    "missing_invitro_labels = torch.full((invivo_labels.shape[0], 1234), -1)\n",
    "missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "batch_labels = {\"lm_label_ids\":torch.cat([invitro_masked_labels[\"lm_label_ids\"], invivo_masked_labels[\"lm_label_ids\"]], dim=0),\n",
    "                \"unmasked_lm_label_ids\":torch.cat([invitro_masked_labels[\"unmasked_lm_label_ids\"], invivo_masked_labels[\"unmasked_lm_label_ids\"]], dim=0),\n",
    "                \"physchem_props\":torch.cat([invitro_masked_labels[\"physchem_props\"], invivo_masked_labels[\"physchem_props\"]], dim=0),\n",
    "                \"invitro\":torch.cat([invitro_labels, missing_invitro_labels], dim=0),\n",
    "                \"invivo\":torch.cat([missing_invivo_labels, invivo_labels], dim=0),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(({'input_ids': tensor([[ 1,  8, 40,  ...,  0,  0,  0],\n",
       "           [ 1, 10,  8,  ...,  0,  0,  0],\n",
       "           [ 1,  8,  9,  ...,  0,  0,  0],\n",
       "           ...,\n",
       "           [ 1,  8,  9,  ...,  0,  0,  0],\n",
       "           [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "           [ 1,  8,  8,  ...,  0,  0,  0]]),\n",
       "   'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0],\n",
       "           [0, 0, 0,  ..., 0, 0, 0]]),\n",
       "   'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "           [1, 1, 1,  ..., 0, 0, 0],\n",
       "           [1, 1, 1,  ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [1, 1, 1,  ..., 0, 0, 0],\n",
       "           [1, 1, 1,  ..., 0, 0, 0],\n",
       "           [1, 1, 1,  ..., 0, 0, 0]])},\n",
       "  {'lm_label_ids': tensor([[-1, -1,  8,  ..., -1, -1, -1],\n",
       "           [-1, -1, -1,  ..., -1, -1, -1],\n",
       "           [-1, -1, -1,  ..., -1, -1, -1],\n",
       "           ...,\n",
       "           [-1, -1,  9,  ..., -1, -1, -1],\n",
       "           [-1, -1, -1,  ..., -1, -1, -1],\n",
       "           [-1, -1, -1,  ..., -1, -1, -1]]),\n",
       "   'unmasked_lm_label_ids': tensor([[ 1,  8,  8,  ...,  0,  0,  0],\n",
       "           [ 1, 10,  8,  ...,  0,  0,  0],\n",
       "           [ 1,  8,  9,  ...,  0,  0,  0],\n",
       "           ...,\n",
       "           [ 1,  8,  9,  ...,  0,  0,  0],\n",
       "           [ 1,  8,  8,  ...,  0,  0,  0],\n",
       "           [ 1,  8,  8,  ...,  0,  0,  0]]),\n",
       "   'physchem_props': tensor([[3.3917e-01, 2.6345e-01, 2.6896e-01,  ..., 7.4484e-13, 4.3766e-19,\n",
       "            4.2211e-17],\n",
       "           [6.8933e-01, 4.7211e-01, 2.7942e-01,  ..., 7.4484e-13, 9.1531e-01,\n",
       "            4.2211e-17],\n",
       "           [8.7214e-01, 8.0679e-02, 1.0575e-01,  ..., 7.4484e-13, 8.8099e-01,\n",
       "            4.2211e-17],\n",
       "           ...,\n",
       "           [9.3418e-01, 9.4143e-01, 9.7565e-01,  ..., 1.0000e+00, 4.3766e-19,\n",
       "            4.2211e-17],\n",
       "           [4.1874e-01, 1.1935e-01, 3.4149e-01,  ..., 7.4484e-13, 4.3766e-19,\n",
       "            4.2211e-17],\n",
       "           [5.8035e-01, 8.0436e-02, 5.1413e-02,  ..., 7.4484e-13, 8.8099e-01,\n",
       "            4.2211e-17]]),\n",
       "   'invitro': tensor([[[ 0.,  0.,  0.,  ..., -1., -1., -1.]],\n",
       "   \n",
       "           [[ 1.,  0.,  0.,  ..., -1., -1., -1.]],\n",
       "   \n",
       "           [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "   \n",
       "           ...,\n",
       "   \n",
       "           [[-1., -1., -1.,  ...,  0.,  0.,  0.]],\n",
       "   \n",
       "           [[-1., -1., -1.,  ...,  0.,  0.,  0.]],\n",
       "   \n",
       "           [[-1., -1., -1.,  ...,  0.,  0.,  0.]]])}),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invivo_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(256) torch.Size([256, 121]) torch.Size([256, 121])\n",
      "tensor(54) torch.Size([54, 114]) torch.Size([54, 114])\n"
     ]
    }
   ],
   "source": [
    "batch_count = 0\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    invitro_clean, invivo_clean, invitro_masked, invivo_masked = batch[0], batch[1], batch[2], batch[3]\n",
    "    (invitro_clean_inputs, _), invitro_clean_valid = invitro_clean\n",
    "    (invivo_clean_inputs, _), invivo_clean_valid = invivo_clean\n",
    "\n",
    "    (invitro_masked_inputs, invitro_masked_labels), invitro_masked_valid = invitro_masked\n",
    "    (invivo_masked_inputs, invivo_masked_labels), invivo_masked_valid = invivo_masked\n",
    "    try:\n",
    "        print(invivo_clean_valid.sum(), invivo_clean_inputs[\"input_ids\"].shape, invivo_masked_labels[\"lm_label_ids\"].shape)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if invivo_masked_inputs is not None:\n",
    "        # two sets of inputs (each with invitro and invivo molecules)\n",
    "        batch_inputs_clean = {k: torch.cat([invitro_clean_inputs[k], invivo_clean_inputs[k]], dim=0) for k in invitro_clean_inputs.keys()}\n",
    "        batch_inputs_corrupted = {k: torch.cat([invitro_masked_inputs[k], invivo_masked_inputs[k]], dim=0) for k in invitro_masked_inputs.keys()}\n",
    "\n",
    "        # concatenate batch outputs (only consider masked labels)\n",
    "        invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "        invivo_labels = invivo_masked_labels[\"invitro\"].squeeze()\n",
    "\n",
    "        missing_invitro_labels = torch.full((invivo_labels.shape[0], 1234), -1)\n",
    "        missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "        batch_labels = {\"lm_label_ids\":torch.cat([invitro_masked_labels[\"lm_label_ids\"], invivo_masked_labels[\"lm_label_ids\"]], dim=0),\n",
    "                        \"unmasked_lm_label_ids\":torch.cat([invitro_masked_labels[\"unmasked_lm_label_ids\"], invivo_masked_labels[\"unmasked_lm_label_ids\"]], dim=0),\n",
    "                        \"physchem_props\":torch.cat([invitro_masked_labels[\"physchem_props\"], invivo_masked_labels[\"physchem_props\"]], dim=0),\n",
    "                        \"invitro\":torch.cat([invitro_labels, missing_invitro_labels], dim=0),\n",
    "                        \"invivo\":torch.cat([missing_invivo_labels, invivo_labels], dim=0),\n",
    "                        }\n",
    "    else:\n",
    "        batch_inputs_clean = invitro_clean_inputs\n",
    "        batch_inputs_corrupted = invitro_masked_inputs\n",
    "\n",
    "        invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "        missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "        batch_labels = invitro_masked_labels\n",
    "        batch_labels[\"invitro\"] = invitro_labels\n",
    "        batch_labels[\"invivo\"] = missing_invivo_labels\n",
    "    \n",
    "    batch_count += 1\n",
    "    if batch_count == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1234]), torch.Size([256, 50]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels[\"invitro\"].shape, batch_labels[\"invivo\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate batch inputs\n",
    "batch_1, batch_2 = batch[0], batch[1]\n",
    "(batch_inputs1, batch_labels1), valid1 = batch_1\n",
    "(batch_inputs2, batch_labels2), valid2 = batch_2\n",
    "batch_inputs = {k: torch.cat([batch_inputs1[k], batch_inputs2[k]], dim=0) for k in batch_inputs1.keys()}\n",
    "\n",
    "# concatenate batch outputs\n",
    "batch_labels = {\"lm_label_ids\":torch.cat([batch_labels1[\"lm_label_ids\"], batch_labels2[\"lm_label_ids\"]], dim=0),\n",
    "                \"unmasked_lm_label_ids\":torch.cat([batch_labels1[\"unmasked_lm_label_ids\"], batch_labels2[\"unmasked_lm_label_ids\"]], dim=0),\n",
    "                \"physchem_props\":torch.cat([batch_labels1[\"physchem_props\"], batch_labels2[\"physchem_props\"]], dim=0),\n",
    "                \"invitro\": batch_labels1[\"invitro\"].squeeze(),\n",
    "                \"invivo\": batch_labels2[\"invitro\"].squeeze(),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_creterian(self, config, data = \"invitro\"):\n",
    "        if data == \"invitro\":\n",
    "            pos_weights_file = config[\"invitro_pos_weights\"]\n",
    "            selected_tasks = config[\"invitro_columns\"]\n",
    "            num_of_tasks = len(selected_tasks)\n",
    "            if self.hparams.beta > 0:\n",
    "                class_weights_file = config[\"invitro_class_weights\"]\n",
    "\n",
    "\n",
    "        if data == \"invivo\":\n",
    "            pos_weights_file = config[\"invivo_pos_weights\"]\n",
    "            selected_tasks = config[\"invivo_columns\"]\n",
    "            num_of_tasks = len(selected_tasks)\n",
    "            if self.hparams.beta > 0:\n",
    "                class_weights_file = config[\"invivo_class_weights\"]\n",
    "\n",
    "\n",
    "        # pos weights\n",
    "        if self.hparams.alpha > 0:\n",
    "            pos_weights = pd.read_csv(pos_weights_file)\n",
    "            if self.hparams.num_of_tasks == 1:\n",
    "                pos_weights = pos_weights.set_index(\"Targets\").reindex([selected_tasks]).weights.values\n",
    "            else:\n",
    "                pos_weights = pos_weights.set_index(\"Targets\").reindex(selected_tasks).weights.values\n",
    "            pos_weights = (config[\"alpha\"] * pos_weights) + (1 - config[\"alpha\"])*1\n",
    "            pos_weights = torch.tensor(pos_weights, device = config[\"device\"])\n",
    "        else:\n",
    "            pos_weights = torch.tensor([1.0]* num_of_tasks, device = config[\"device\"])\n",
    "\n",
    "        alpha_null = torch.isnan(pos_weights).any()\n",
    "        assert not alpha_null, \"There are null values in the pos_weight tensor\"\n",
    "\n",
    "        # class weights\n",
    "        if self.hparams.beta > 0:\n",
    "            if num_of_tasks > 1:\n",
    "                class_weights = pd.read_csv(class_weights_file)\n",
    "                class_weights = class_weights.set_index(\"Targets\").reindex(selected_tasks).weights.values\n",
    "                class_weights = (config[\"beta\"] * class_weights) + (1 - config[\"beta\"])*1\n",
    "                class_weights = torch.tensor(class_weights, device = config[\"device\"])\n",
    "            else:\n",
    "                class_weights = torch.tensor([1.0], device = config[\"device\"])\n",
    "\n",
    "            beta_null = torch.isnan(class_weights).any()\n",
    "            assert not beta_null, \"There are null values in the class_weight tensor\"\n",
    "\n",
    "            # train_weighted loss, validation no weights\n",
    "            weighted_creterien =  nn.BCEWithLogitsLoss(reduction=\"none\", \n",
    "                                                            pos_weight= pos_weights,\n",
    "                                                            weight= class_weights)\n",
    "        else:\n",
    "            weighted_creterien =  nn.BCEWithLogitsLoss(reduction=\"none\", \n",
    "                                                            pos_weight= pos_weights)\n",
    "        \n",
    "        FL = FocalLoss(gamma=config['gamma'], pos_weight= pos_weights)\n",
    "        non_weighted_creterian =  nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "        return non_weighted_creterian, weighted_creterien, FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ece(y_true, y_prob, n_bins=10, equal_intervals = True):\n",
    "    # Calculate bin boundaries\n",
    "    if equal_intervals == True: # ECE\n",
    "        bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    else:                       # ACE\n",
    "        bin_boundaries = np.percentile(y_prob, np.linspace(0, 100, n_bins + 1))\n",
    "    \n",
    "    # Calculate bin indices\n",
    "    bin_indices = np.digitize(y_prob, bin_boundaries[1:-1])\n",
    "    \n",
    "    ece = 0\n",
    "    total_samples = len(y_true)\n",
    "    \n",
    "    # Calculate ECE\n",
    "    for bin_idx in range(n_bins):\n",
    "        # Filter samples within the bin\n",
    "        bin_mask = bin_indices == bin_idx\n",
    "        bin_samples = np.sum(bin_mask)\n",
    "        \n",
    "        if bin_samples > 0:\n",
    "            # Calculate accuracy and confidence for the bin\n",
    "            bin_accuracy = np.mean(y_true[bin_mask])\n",
    "            bin_confidence = np.mean(y_prob[bin_mask])\n",
    "        \n",
    "            # Update ECE\n",
    "            ece += (bin_samples / total_samples) * np.abs(bin_accuracy - bin_confidence)\n",
    "\n",
    "    return ece\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma, pos_weight):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.w_p = pos_weight\n",
    "\n",
    "\n",
    "    def forward(self,y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Focal Loss function for binary classification.\n",
    "\n",
    "        Arguments:\n",
    "        y_true -- true binary labels (0 or 1), torch.Tensor\n",
    "        y_pred -- predicted probabilities for the positive class, torch.Tensor\n",
    "\n",
    "        Returns:\n",
    "        Focal Loss\n",
    "        \"\"\"\n",
    "        # Compute class weight\n",
    "        p = torch.sigmoid(y_pred)\n",
    "\n",
    "        # Compute focal loss for positive and negative examples\n",
    "        focal_loss_pos = - self.w_p * (1 - p) ** self.gamma * y_true * torch.log(p.clamp(min=1e-8))\n",
    "        focal_loss_pos_neg = - p ** self.gamma * (1 - y_true) * torch.log((1 - p).clamp(min=1e-8))\n",
    "\n",
    "        return focal_loss_pos + focal_loss_pos_neg\n",
    "    \n",
    "class MolbertModel(pl.LightningModule):\n",
    "    def __init__(self, args: Namespace):\n",
    "        super().__init__()\n",
    "\n",
    "        self.training_step_invitro_labels, self.training_step_invitro_pred = [],[]\n",
    "        self.training_step_invivo_labels, self.training_step_invivo_pred = [],[]\n",
    "\n",
    "        self.val_step_invitro_labels, self.val_step_invitro_pred = [],[]\n",
    "        self.val_step_invivo_labels, self.val_step_invivo_pred = [],[]\n",
    "\n",
    "        self.hparams = args\n",
    "        self.non_weighted_creterian, self.invitro_weighted_creterien, self.invitro_FL = self.get_creterian(args, targets = \"invitro\")\n",
    "        self.non_weighted_creterian, self.invivo_weighted_creterien, self.invivo_FL = self.get_creterian(args, targets = \"invivo\")\n",
    "\n",
    "\n",
    "        # get model, load pretrained weights, and freeze encoder        \n",
    "        model = SmilesMolbertModel(self.hparams)\n",
    "        if self.hparams.pretrained_model:\n",
    "            checkpoint = torch.load(self.hparams.pretrained_model_path, map_location=lambda storage, loc: storage)\n",
    "            model.load_state_dict(checkpoint['state_dict'], strict = False)\n",
    "        \n",
    "        if self.hparams.freeze_level:\n",
    "            # Freeze model\n",
    "            MolbertModel.freeze_network(model, self.hparams.freeze_level)\n",
    "\n",
    "        self.encoder = model.model.bert\n",
    "        self.Masked_LM_task = model.model.tasks[0]\n",
    "        self.Physchem_task = model.model.tasks[1]\n",
    "        self.invitro_task = model.model.tasks[2]\n",
    "        self.invivo_task = model.model.tasks[3]\n",
    "\n",
    "        #3checkpoint = torch.load(self.hparams.pretrained_crash_model, map_location=lambda storage, loc: storage)\n",
    "        #self.load_state_dict(checkpoint['state_dict'], strict = True)\n",
    "\n",
    "    def forward(self, batch_inputs):\n",
    "        #input_ids =  batch_inputs[\"input_ids\"]\n",
    "        #token_type_ids = batch_inputs[\"token_type_ids\"]\n",
    "        #attention_mask = batch_inputs[\"attention_mask\"]\n",
    "\n",
    "        # msking should be here \n",
    "        # masked_embedding = encoder (masked_tokens)\n",
    "        # clean_embedding = encoder (cleaned_tokens)\n",
    "        sequence_output, pooled_output = self.encoder(**batch_inputs)\n",
    "        Masked_token_pred = self.Masked_LM_task(sequence_output, pooled_output)\n",
    "        Physchem_pred = self.Physchem_task(sequence_output, pooled_output)\n",
    "        invitro_pred = self.invitro_task(sequence_output, pooled_output)\n",
    "        invivo_pred = self.invivo_task(sequence_output, pooled_output)\n",
    "\n",
    "        return Masked_token_pred, Physchem_pred, invitro_pred, invivo_pred\n",
    "    \n",
    "    def get_creterian(self, config, targets):\n",
    "        if targets == \"invitro\":\n",
    "            pos_weights_file = config[\"invitro_pos_weights\"]\n",
    "            selected_tasks = config[\"invitro_columns\"]\n",
    "            num_of_tasks = len(selected_tasks)\n",
    "            if self.hparams.beta > 0:\n",
    "                class_weights_file = config[\"invitro_class_weights\"]\n",
    "\n",
    "\n",
    "        if targets == \"invivo\":\n",
    "            pos_weights_file = config[\"invivo_pos_weights\"]\n",
    "            selected_tasks = config[\"invivo_columns\"]\n",
    "            num_of_tasks = len(selected_tasks)\n",
    "            if self.hparams.beta > 0:\n",
    "                class_weights_file = config[\"invivo_class_weights\"]\n",
    "\n",
    "\n",
    "        # pos weights\n",
    "        if self.hparams.alpha > 0:\n",
    "            pos_weights = pd.read_csv(pos_weights_file)\n",
    "            if self.hparams.num_of_tasks == 1:\n",
    "                pos_weights = pos_weights.set_index(\"Targets\").reindex([selected_tasks]).weights.values\n",
    "            else:\n",
    "                pos_weights = pos_weights.set_index(\"Targets\").reindex(selected_tasks).weights.values\n",
    "            pos_weights = (config[\"alpha\"] * pos_weights) + (1 - config[\"alpha\"])*1\n",
    "            pos_weights = torch.tensor(pos_weights, device = config[\"device\"])\n",
    "        else:\n",
    "            pos_weights = torch.tensor([1.0]* num_of_tasks, device = config[\"device\"])\n",
    "\n",
    "        alpha_null = torch.isnan(pos_weights).any()\n",
    "        assert not alpha_null, \"There are null values in the pos_weight tensor\"\n",
    "\n",
    "        # class weights\n",
    "        if self.hparams.beta > 0:\n",
    "            if num_of_tasks > 1:\n",
    "                class_weights = pd.read_csv(class_weights_file)\n",
    "                class_weights = class_weights.set_index(\"Targets\").reindex(selected_tasks).weights.values\n",
    "                class_weights = (config[\"beta\"] * class_weights) + (1 - config[\"beta\"])*1\n",
    "                class_weights = torch.tensor(class_weights, device = config[\"device\"])\n",
    "            else:\n",
    "                class_weights = torch.tensor([1.0], device = config[\"device\"])\n",
    "\n",
    "            beta_null = torch.isnan(class_weights).any()\n",
    "            assert not beta_null, \"There are null values in the class_weight tensor\"\n",
    "\n",
    "            # train_weighted loss, validation no weights\n",
    "            weighted_creterien =  nn.BCEWithLogitsLoss(reduction=\"none\", \n",
    "                                                            pos_weight= pos_weights,\n",
    "                                                            weight= class_weights)\n",
    "        else:\n",
    "            weighted_creterien =  nn.BCEWithLogitsLoss(reduction=\"none\", \n",
    "                                                            pos_weight= pos_weights)\n",
    "        \n",
    "        FL = FocalLoss(gamma=config['gamma'], pos_weight= pos_weights)\n",
    "        non_weighted_creterian =  nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "        return non_weighted_creterian, weighted_creterien, FL\n",
    "    \n",
    "    def l2_regularization(self):\n",
    "        device = torch.device('cuda')\n",
    "        l2_reg = torch.tensor(0., requires_grad=True, device=device)\n",
    "        \n",
    "        # Apply only on weights, exclude bias\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                l2_reg = l2_reg + torch.norm(param, p=2)\n",
    "        return l2_reg\n",
    "    \n",
    "    def add_weight_decay(self, skip_list=()):\n",
    "        decay = []\n",
    "        no_decay = []\n",
    "        for name, param in self.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            if len(param.shape) == 1 or name in skip_list:\n",
    "                no_decay.append(param)\n",
    "            else:\n",
    "                decay.append(param)\n",
    "            \n",
    "        return [\n",
    "            {'params': no_decay, 'weight_decay': 0.},\n",
    "            {'params': decay, 'weight_decay': self.hparams.l2_lambda}]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer_grouped_parameters = self.add_weight_decay(skip_list=())\n",
    "\n",
    "        if self.hparams.optim == 'SGD':\n",
    "            optimizer = torch.optim.SGD(optimizer_grouped_parameters, \n",
    "                                             lr=self.hparams.learning_rate)\n",
    "        if self.hparams.optim == 'Adam':\n",
    "            optimizer = torch.optim.Adam(optimizer_grouped_parameters, \n",
    "                                             lr=self.hparams.learning_rate)\n",
    "        if self.hparams.optim == 'AdamW':    \n",
    "            optimizer = AdamW(optimizer_grouped_parameters, \n",
    "                                lr=self.hparams.learning_rate, \n",
    "                                eps=self.hparams.adam_epsilon)\n",
    "        \n",
    "        scheduler = self._initialise_lr_scheduler(optimizer)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def _initialise_lr_scheduler(self, optimizer):\n",
    "\n",
    "        \n",
    "        num_training_steps = self.hparams.num_batches // self.hparams.accumulate_grad_batches * self.hparams.max_epochs\n",
    "        warmup_steps = int(num_training_steps * self.hparams.warmup_proportion)\n",
    "\n",
    "        if self.hparams.learning_rate_scheduler == 'linear_with_warmup':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps\n",
    "            )\n",
    "        elif self.hparams.learning_rate_scheduler == 'cosine_with_hard_restarts_warmup':\n",
    "            scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps, num_cycles=1\n",
    "            )\n",
    "        elif self.hparams.learning_rate_scheduler == 'cosine_schedule_with_warmup':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps\n",
    "            )\n",
    "        elif self.hparams.learning_rate_scheduler == 'constant_schedule_with_warmup':\n",
    "            scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps)\n",
    "\n",
    "        elif self.hparams.learning_rate_scheduler == 'cosine_annealing_warm_restarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, warmup_steps)\n",
    "        elif self.hparams.learning_rate_scheduler == 'reduce_on_plateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer)\n",
    "        elif self.hparams.learning_rate_scheduler == 'constant':\n",
    "            scheduler = StepLR(optimizer, 10, gamma=1.0)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'learning_rate_scheduler needs to be one of '\n",
    "                f'linear_with_warmup, cosine_with_hard_restarts_warmup, cosine_schedule_with_warmup, '\n",
    "                f'constant_schedule_with_warmup, cosine_annealing_warm_restarts, reduce_on_plateau, '\n",
    "                f'step_lr. '\n",
    "                f'Given: {self.hparams.learning_rate_scheduler}'\n",
    "            )\n",
    "\n",
    "        logger.info(\n",
    "            f'SCHEDULER: {self.hparams.learning_rate_scheduler} '\n",
    "            f'num_batches={self.hparams.num_batches} '\n",
    "            f'num_training_steps={num_training_steps} '\n",
    "            f'warmup_steps={warmup_steps}'\n",
    "        )\n",
    "\n",
    "        return {'scheduler': scheduler, 'monitor': 'valid_loss', 'interval': 'step', 'frequency': 1}\n",
    "    \n",
    "    def _compute_loss(self, y, y_hat, targets):\n",
    "        if self.hparams.num_of_tasks == 1:\n",
    "            y = y.unsqueeze(1)\n",
    "        # compute losses, wiht masking\n",
    "        if self.hparams.missing == 'nan':\n",
    "            nan_mask = torch.isnan(y)\n",
    "            y[nan_mask] = -1\n",
    "            #y = torch.nan_to_num(y, nan = -1), for newer version\n",
    "        \n",
    "        # masks\n",
    "        valid_label_mask = (y != -1).float()\n",
    "        pos_label_mask = (y == 1)\n",
    "        negative_label_mask = (y == 0)\n",
    "\n",
    "        if targets == \"invitro\":\n",
    "            if self.hparams.loss_type == \"BCE\":\n",
    "                weighted_loss = self.invitro_weighted_creterien(y_hat, y) * valid_label_mask\n",
    "            if self.hparams.loss_type == \"Focal_loss\":\n",
    "                weighted_loss = self.invitro_FL(y_hat, y)* valid_label_mask\n",
    "\n",
    "        if targets == \"invivo\":\n",
    "            if self.hparams.loss_type == \"BCE\":\n",
    "                weighted_loss = self.invivo_weighted_creterien(y_hat, y) * valid_label_mask\n",
    "            if self.hparams.loss_type == \"Focal_loss\":\n",
    "                weighted_loss = self.invivo_FL(y_hat, y)* valid_label_mask\n",
    "\n",
    "        Non_weighted_loss = self.non_weighted_creterian(y_hat, y) * valid_label_mask\n",
    "        \n",
    "        # Non_weighted_loss, positive negative loss\n",
    "        pos_loss = Non_weighted_loss * pos_label_mask\n",
    "        neg_loss = Non_weighted_loss * negative_label_mask\n",
    "        pos_loss = pos_loss.sum() / pos_label_mask.sum()\n",
    "        neg_loss = neg_loss.sum() / negative_label_mask.sum()\n",
    "    \n",
    "        # compute mean loss\n",
    "        Non_weighted_loss = Non_weighted_loss.sum() / valid_label_mask.sum()\n",
    "        weighted_loss = weighted_loss.sum() / valid_label_mask.sum()\n",
    "\n",
    "        return weighted_loss, Non_weighted_loss, pos_loss, neg_loss\n",
    "    \n",
    "    def MaskedLM_loss(self, batch_labels, batch_predictions):\n",
    "\n",
    "        loss_fn = CrossEntropyLoss(ignore_index=-1)\n",
    "        vocab_size = self.hparams.vocab_size\n",
    "        loss = loss_fn(batch_predictions.view(-1, vocab_size), \n",
    "                batch_labels['lm_label_ids'].view(-1))  \n",
    "        return loss  \n",
    "    \n",
    "    def Physchem_loss(self, batch_labels, batch_predictions):\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        loss = loss_fn(batch_predictions, batch_labels[\"physchem_props\"])\n",
    "        return loss  \n",
    "        \n",
    "    def extract_corrupted_cleaned_data(self, batch):\n",
    "        invitro_clean, invivo_clean, invitro_masked, invivo_masked = batch[0], batch[1], batch[2], batch[3]\n",
    "        (invitro_clean_inputs, _), _ = invitro_clean\n",
    "        (invivo_clean_inputs, _), _ = invivo_clean\n",
    "\n",
    "        (invitro_masked_inputs, invitro_masked_labels), _ = invitro_masked\n",
    "        (invivo_masked_inputs, invivo_masked_labels), _ = invivo_masked\n",
    "\n",
    "        if invivo_masked_inputs is not None:\n",
    "            # two sets of inputs (each with invitro and invivo molecules)\n",
    "            batch_inputs_clean = {k: torch.cat([invitro_clean_inputs[k], invivo_clean_inputs[k]], dim=0) for k in invitro_clean_inputs.keys()}\n",
    "            batch_inputs_corrupted = {k: torch.cat([invitro_masked_inputs[k], invivo_masked_inputs[k]], dim=0) for k in invitro_masked_inputs.keys()}\n",
    "\n",
    "            # concatenate batch outputs (only consider masked labels)\n",
    "            invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "            invivo_labels = invivo_masked_labels[\"invitro\"].squeeze()\n",
    "\n",
    "            missing_invitro_labels = torch.full((invivo_labels.shape[0], 1234), -1)\n",
    "            missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "            batch_labels = {\"lm_label_ids\":torch.cat([invitro_masked_labels[\"lm_label_ids\"], invivo_masked_labels[\"lm_label_ids\"]], dim=0),\n",
    "                            \"unmasked_lm_label_ids\":torch.cat([invitro_masked_labels[\"unmasked_lm_label_ids\"], invivo_masked_labels[\"unmasked_lm_label_ids\"]], dim=0),\n",
    "                            \"physchem_props\":torch.cat([invitro_masked_labels[\"physchem_props\"], invivo_masked_labels[\"physchem_props\"]], dim=0),\n",
    "                            \"invitro\":torch.cat([invitro_labels, missing_invitro_labels], dim=0),\n",
    "                            \"invivo\":torch.cat([missing_invivo_labels, invivo_labels], dim=0),\n",
    "                            }\n",
    "        else:\n",
    "            batch_inputs_clean = invitro_clean_inputs\n",
    "            batch_inputs_corrupted = invitro_masked_inputs\n",
    "\n",
    "            invitro_labels = invitro_masked_labels[\"invitro\"].squeeze()\n",
    "            missing_invivo_labels = torch.full((invitro_labels.shape[0], 50), -1)\n",
    "\n",
    "            batch_labels = invitro_masked_labels\n",
    "            batch_labels[\"invitro\"] = invitro_labels\n",
    "            batch_labels[\"invivo\"] = missing_invivo_labels\n",
    "        \n",
    "        return batch_inputs_clean, batch_inputs_corrupted, batch_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_inputs_clean, batch_inputs_corrupted, batch_labels = self.extract_corrupted_cleaned_data(batch)\n",
    "        \n",
    "        # compute forward pass with clean sequence\n",
    "        _, Physchem_pred, invitro_pred, invivo_pred = self.forward(batch_inputs_clean)\n",
    "\n",
    "        # compute forward pass with corrupted sequence\n",
    "        Masked_token_pred, _, _, _ = self.forward(batch_inputs_corrupted)\n",
    "\n",
    "        # classification loss, masking loss + MSE loss\n",
    "        masking_loss = self.MaskedLM_loss(batch_labels, Masked_token_pred) \n",
    "        physchem_loss = self.Physchem_loss(batch_labels, Physchem_pred)\n",
    "        invitro_weighted_loss, invitro_Non_weighted_loss, invitro_pos_loss, invitro_neg_loss = self._compute_loss(batch_labels[\"invitro\"], invitro_pred, targets = \"invitro\") \n",
    "        invivo_weighted_loss, invivo_Non_weighted_loss, invivo_pos_loss, invivo_neg_loss = self._compute_loss(batch_labels[\"invivo\"], invitro_pred, targets = \"invivo\") \n",
    "        \n",
    "        # total loss\n",
    "        total_loss = masking_loss + physchem_loss + invitro_weighted_loss + self.hparams.invivo_scale * invivo_weighted_loss\n",
    "        \n",
    "        # save predictions for accuracy calculations\n",
    "        self.training_step_invitro_labels.append(batch_labels[\"invitro\"].long().detach().cpu())\n",
    "        self.training_step_invitro_pred.append(torch.sigmoid(invitro_pred.detach().cpu()))\n",
    "\n",
    "        self.training_step_invivo_labels.append(batch_labels[\"invivo\"].long().detach().cpu())\n",
    "        self.training_step_invivo_pred.append(torch.sigmoid(invivo_pred.detach().cpu()))\n",
    "        \n",
    "        return {\n",
    "                \"loss\": total_loss,\n",
    "                \"masking_loss\": masking_loss,\n",
    "                \"physchem_loss\": physchem_loss,\n",
    "                \"invitro_weighted_loss\": invitro_weighted_loss,\n",
    "                \"invitro_Non_weighted_loss\": invitro_Non_weighted_loss,\n",
    "                \"invitro_pos_loss\": invitro_pos_loss,\n",
    "                \"invitro_neg_loss\": invitro_neg_loss,\n",
    "                \"invivo_weighted_loss\": invivo_weighted_loss,\n",
    "                \"invivo_Non_weighted_loss\": invivo_Non_weighted_loss,\n",
    "                \"invivo_pos_loss\": invivo_pos_loss,\n",
    "                \"invivo_neg_loss\": invivo_neg_loss\n",
    "            }\n",
    "    \n",
    "    def training_step_end(self, outputs):\n",
    "        # Define the step prefix\n",
    "        step_prefix = \"train_\"\n",
    "        \n",
    "        # Calculate mean losses\n",
    "        losses = {key: outputs[key].mean() for key in outputs.keys()}\n",
    "        \n",
    "        # Log the losses with WandB\n",
    "        log_dict = {f'{step_prefix}{key}_step': value.item() for key, value in losses.items()}\n",
    "        log_dict[\"global_step\"] = self.trainer.global_step\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "        ################################################################\n",
    "        # save checkpoint in between\n",
    "        ################################################################\n",
    "        interval_batches = int(0.1 * self.hparams.num_batches)\n",
    "        epoch, global_step = self.trainer.current_epoch, self.trainer.global_step + 1\n",
    "        if (global_step % interval_batches == 0) and (epoch == 0):\n",
    "            # Log the current epoch and step for clarity\n",
    "            print(f\"Saving checkpoint at epoch {epoch}, step {global_step}\")\n",
    "            filename = f\"epoch_{epoch}_step_{global_step}.ckpt\"\n",
    "            ckpt_path = os.path.join(self.trainer.checkpoint_callback.dirpath, filename)\n",
    "            self.trainer.save_checkpoint(ckpt_path)\n",
    "        return losses\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_inputs_clean, batch_inputs_corrupted, batch_labels = self.extract_corrupted_cleaned_data(batch)\n",
    "            \n",
    "            # compute forward pass with clean sequence\n",
    "            _, Physchem_pred, invitro_pred, invivo_pred = self.forward(batch_inputs_clean)\n",
    "\n",
    "            # compute forward pass with corrupted sequence\n",
    "            Masked_token_pred, _, _, _ = self.forward(batch_inputs_corrupted)\n",
    "\n",
    "            # classification loss, masking loss + MSE loss\n",
    "            masking_loss = self.MaskedLM_loss(batch_labels, Masked_token_pred) \n",
    "            physchem_loss = self.Physchem_loss(batch_labels, Physchem_pred)\n",
    "            invitro_weighted_loss, invitro_Non_weighted_loss, invitro_pos_loss, invitro_neg_loss = self._compute_loss(batch_labels[\"invitro\"], invitro_pred) \n",
    "            invivo_weighted_loss, invivo_Non_weighted_loss, invivo_pos_loss, invivo_neg_loss = self._compute_loss(batch_labels[\"invivo\"], invitro_pred) \n",
    "            \n",
    "            # total loss\n",
    "            total_loss = masking_loss + physchem_loss + invitro_weighted_loss + self.hparams.invivo_scale * invivo_weighted_loss\n",
    "            \n",
    "            # save predictions for accuracy calculations\n",
    "            self.val_step_invitro_labels.append(batch_labels[\"invitro\"].long().detach().cpu())\n",
    "            self.val_step_invitro_pred.append(torch.sigmoid(invitro_pred.detach().cpu()))\n",
    "\n",
    "            self.val_step_invivo_labels.append(batch_labels[\"invivo\"].long().detach().cpu())\n",
    "            self.val_step_invivo_pred.append(torch.sigmoid(invivo_pred.detach().cpu()))\n",
    "        \n",
    "        return {\n",
    "                \"loss\": total_loss,\n",
    "                \"masking_loss\": masking_loss,\n",
    "                \"physchem_loss\": physchem_loss,\n",
    "                \"invitro_weighted_loss\": invitro_weighted_loss,\n",
    "                \"invitro_Non_weighted_loss\": invitro_Non_weighted_loss,\n",
    "                \"invitro_pos_loss\": invitro_pos_loss,\n",
    "                \"invitro_neg_loss\": invitro_neg_loss,\n",
    "                \"invivo_weighted_loss\": invivo_weighted_loss,\n",
    "                \"invivo_Non_weighted_loss\": invivo_Non_weighted_loss,\n",
    "                \"invivo_pos_loss\": invivo_pos_loss,\n",
    "                \"invivo_neg_loss\": invivo_neg_loss\n",
    "            }\n",
    "    \n",
    "    def validation_step_end(self, outputs):\n",
    "        # Define the step prefix\n",
    "        step_prefix = \"val_\"\n",
    "\n",
    "       # Calculate mean losses\n",
    "        losses = {key: outputs[key].mean() for key in outputs.keys()}\n",
    "        \n",
    "        # Log the losses with WandB\n",
    "        log_dict = {f'{step_prefix}{key}_step': value.item() for key, value in losses.items()}\n",
    "        log_dict[\"global_step\"] = self.trainer.global_step\n",
    "        wandb.log(log_dict)\n",
    "        return losses\n",
    "    \n",
    "    def on_epoch_start(self):\n",
    "        # Check if current epoch is greater than or equal to the desired epoch to unfreeze\n",
    "        if self.current_epoch == 0:\n",
    "            epoch, global_step = self.trainer.current_epoch, self.trainer.global_step\n",
    "            print(f\"Saving checkpoint before first epoch/step\")\n",
    "            filename = f\"epoch_{epoch}_step_{global_step}.ckpt\"\n",
    "            ckpt_path = os.path.join(self.trainer.checkpoint_callback.dirpath, filename)\n",
    "            self.trainer.save_checkpoint(ckpt_path)\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        step_prefix = \"train_\"\n",
    "        \n",
    "        # Calculate mean losses\n",
    "        losses = {key: torch.stack([x[key] for x in outputs]).mean().item() for key in outputs[0].keys()}\n",
    "\n",
    "        # Log the losses with WandB\n",
    "        log_dict = {f'{step_prefix}{key}_epoch': loss for key, loss in losses.items()}\n",
    "        log_dict.update({\n",
    "            \"current_epoch\": self.trainer.current_epoch + 1,\n",
    "            \"global_step\": self.trainer.global_step\n",
    "        })\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "        # Log the learning rate at the end of each epoch\n",
    "        lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        wandb.log({'learning_rate': lr})\n",
    "\n",
    "        # Collect predictions and true labels for the complete training set\n",
    "        invitro_labels = torch.cat(self.training_step_invitro_labels, dim=0)\n",
    "        invitro_pred = torch.cat(self.training_step_invitro_pred, dim=0)\n",
    "\n",
    "        invivo_labels = torch.cat(self.training_step_invivo_labels, dim=0)\n",
    "        invivo_pred = torch.cat(self.training_step_invivo_pred, dim=0)\n",
    "\n",
    "        invitro_score_list =  self.compute_metrics(invitro_labels, invitro_pred, targets_type = \"invitro\")\n",
    "        invivo_score_list =  self.compute_metrics(invivo_labels, invivo_pred, targets_type = \"invitro\")\n",
    "\n",
    "        metric = ['roc_score', 'blc_acc', 'sensitivity', 'specificity', 'AUPR', 'f1_score', 'average_precision','ECE_score','ACE_score']\n",
    "            \n",
    "        for i, score in enumerate(invitro_score_list):\n",
    "            wandb.log({f'train_{metric[i]}':score.item()})\n",
    "\n",
    "        for i, score in enumerate(invivo_score_list):\n",
    "            wandb.log({f'train_{metric[i]}':score.item()})\n",
    "        \n",
    "        # Clear the lists to free memory for the next epoch\n",
    "        self.training_step_invitro_labels.clear()\n",
    "        self.training_step_invitro_pred.clear()\n",
    "        self.training_step_invivo_labels.clear()\n",
    "        self.training_step_invivo_pred.clear()\n",
    "        del invitro_labels,invitro_pred, invivo_labels, invivo_pred\n",
    "\n",
    "        return losses\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        step_prefix = \"val_\"\n",
    "        \n",
    "         # Calculate mean losses\n",
    "        # Calculate mean losses\n",
    "        losses = {key: torch.stack([x[key] for x in outputs]).mean().item() for key in outputs[0].keys()}\n",
    "\n",
    "        # Log the losses with WandB\n",
    "        log_dict = {f'{step_prefix}{key}_epoch': loss for key, loss in losses.items()}\n",
    "        log_dict.update({\n",
    "            \"current_epoch\": self.trainer.current_epoch + 1,\n",
    "            \"global_step\": self.trainer.global_step\n",
    "        })\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "\n",
    "        # Collect predictions and true labels for the complete training set\n",
    "        invitro_labels = torch.cat(self.val_step_invitro_labels, dim=0)\n",
    "        invitro_pred = torch.cat(self.val_step_invitro_pred, dim=0)\n",
    "\n",
    "        invivo_labels = torch.cat(self.val_step_invivo_labels, dim=0)\n",
    "        invivo_pred = torch.cat(self.val_step_invivo_pred, dim=0)\n",
    "\n",
    "        invitro_score_list =  self.compute_metrics(invitro_labels, invitro_pred, targets_type = \"invitro\")\n",
    "        invivo_score_list =  self.compute_metrics(invivo_labels, invivo_pred, targets_type = \"invivo\")\n",
    "\n",
    "        metric = ['roc_score', 'blc_acc', 'sensitivity', 'specificity', 'AUPR', 'f1_score', 'average_precision','ECE_score','ACE_score']\n",
    "            \n",
    "        for i, score in enumerate(invitro_score_list):\n",
    "            wandb.log({f'val_{metric[i]}':score.item()})\n",
    "\n",
    "        for i, score in enumerate(invivo_score_list):\n",
    "            wandb.log({f'val_{metric[i]}':score.item()})\n",
    "        \n",
    "        # Clear the lists to free memory for the next epoch\n",
    "        self.val_step_invitro_labels.clear()\n",
    "        self.val_step_invitro_pred.clear()\n",
    "        self.val_step_invivo_labels.clear()\n",
    "        self.val_step_invivo_pred.clear()\n",
    "        del invitro_labels,invitro_pred, invivo_labels, invivo_pred\n",
    "\n",
    "\n",
    "        return losses\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        weight_norm = self.l2_regularization()\n",
    "        tensorboard_logs = {'weight_norm': weight_norm}\n",
    "        wandb.log(tensorboard_logs)\n",
    "\n",
    "       # Then clean the cache\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        for gpu_id in range(num_gpus):\n",
    "            with torch.cuda.device(f'cuda:{gpu_id}'):\n",
    "                torch.cuda.empty_cache()\n",
    "        # then collect the garbage\n",
    "        gc.collect()\n",
    "        print(\"!!!!!!!!! ALL CLEAR !!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "    def compute_metrics(self, y_true, y_pred, targets_type): \n",
    "        self.eval()\n",
    "\n",
    "        targets =  y_true.cpu().detach().tolist()\n",
    "        preds = y_pred.cpu().detach().tolist()\n",
    "\n",
    "        if targets_type == \"invitro\":\n",
    "            num_of_tasks = len(self.hparams.invitro_columns)\n",
    "        if targets_type == \"invivo\":\n",
    "            num_of_tasks = len(self.hparams.invivo_columns)\n",
    "\n",
    "        targets = np.array(targets).reshape(-1,num_of_tasks)\n",
    "        preds = np.array(preds).reshape(-1,num_of_tasks)\n",
    "\n",
    "        #if self.hparams.missing == 'nan':\n",
    "        #    mask = ~np.isnan(targets)\n",
    "        \n",
    "        mask = (targets != -1)\n",
    "\n",
    "        roc_score, blc_acc, sensitivity, specificity, AUPR, f1, average_precision = [],[],[],[],[],[],[]\n",
    "        ECE_score, ACE_score = [],[]\n",
    "\n",
    "        for i in range(self.hparams.num_of_tasks):\n",
    "            \n",
    "            try:\n",
    "                # get valid targets, and convert logits to prob\n",
    "                valid_targets = targets[:,i][mask[:,i]]\n",
    "                valid_preds = expit(preds[:,i][mask[:,i]])\n",
    "                ECE= compute_ece(valid_targets, valid_preds, n_bins=10, equal_intervals = True)\n",
    "                ACE = compute_ece(valid_targets, valid_preds, n_bins=10, equal_intervals = False)\n",
    "                ECE_score.append(ECE)\n",
    "                ACE_score.append(ACE)\n",
    "            except:\n",
    "                ECE_score.append(np.nan)\n",
    "                ACE_score.append(np.nan)\n",
    "\n",
    "            try:\n",
    "                # ROC_AUC\n",
    "                fpr, tpr, th = roc_curve(valid_targets, valid_preds)\n",
    "                roc_score.append(auc(fpr, tpr))\n",
    "\n",
    "                # Balanced accuracy\n",
    "                balanced_accuracy = (tpr + (1 - fpr)) / 2\n",
    "                blc_acc.append(np.max(balanced_accuracy))\n",
    "\n",
    "                # sensitivity, specificity\n",
    "                optimal_threshold_index = np.argmax(balanced_accuracy)\n",
    "                optimal_threshold = th[optimal_threshold_index]\n",
    "                sensitivity.append(tpr[optimal_threshold_index])\n",
    "                specificity.append(1 - fpr[optimal_threshold_index])\n",
    "\n",
    "                # AUPR, F1\n",
    "                precision, recall, thresholds = precision_recall_curve(valid_targets, valid_preds)\n",
    "                AUPR.append(auc(recall, precision))\n",
    "                f1_sc = f1_score(valid_targets, self.prob_to_labels(valid_preds, optimal_threshold))\n",
    "                f1.append(f1_sc)\n",
    "                average_precision.append(average_precision_score(valid_targets, valid_preds))\n",
    "                \n",
    "            except:\n",
    "                roc_score.append(np.nan)\n",
    "                AUPR.append(np.nan)\n",
    "                average_precision.append(np.nan)\n",
    "                #print('Performance metric is null')\n",
    "                \n",
    "        self.train()\n",
    "        return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR), np.nanmean(f1), np.nanmean(average_precision),np.nanmean(ECE_score),np.nanmean(ACE_score)\n",
    "\n",
    "    \n",
    "    def prob_to_labels(self, pred, threshold):\n",
    "\t    return (pred >= threshold).astype('int')\n",
    "\n",
    "    def unfreeze_model(self):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    @staticmethod\n",
    "    def freeze_network(model, freeze_level: int):\n",
    "        \"\"\"\n",
    "        Freezes specific layers of the model depending on the freeze_level argument:\n",
    "\n",
    "         0: freeze nothing\n",
    "        -1: freeze all BERT weights but not the task head\n",
    "        -2: freeze the pooling layer\n",
    "        -3: freeze the embedding layer\n",
    "        -4: freeze the task head but not the base layer\n",
    "        n>0: freeze the bottom n layers of the base model.\n",
    "        \"\"\"\n",
    "\n",
    "        model_bert = model.model.bert\n",
    "        model_tasks = model.model.tasks\n",
    "\n",
    "        model_bert_encoder = model.model.bert.encoder\n",
    "        model_bert_pooler = model.model.bert.pooler\n",
    "        model_bert_embeddings = model.model.bert.embeddings\n",
    "\n",
    "        if freeze_level == 0:\n",
    "            # freeze nothing\n",
    "            return\n",
    "\n",
    "        elif freeze_level > 0:\n",
    "            # freeze the encoder/transformer\n",
    "            n_encoder_layers = len(model_bert_encoder.layer)\n",
    "\n",
    "            # we'll always freeze layers bottom up - starting from layers closest to the embeddings\n",
    "            frozen_layers = min(freeze_level, n_encoder_layers)\n",
    "            #\n",
    "            for i in range(frozen_layers):\n",
    "                layer = model_bert_encoder.layer[i]\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -1:\n",
    "            # freeze everything bert\n",
    "            for param in model_bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -2:\n",
    "            # freeze the pooling layer\n",
    "            for param in model_bert_pooler.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -3:\n",
    "            # freeze the embedding layer\n",
    "            for param in model_bert_embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        elif freeze_level == -4:\n",
    "            # freeze the task head\n",
    "            for param in model_tasks.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def compute_interval_wise_means(self, outputs, interval_size):\n",
    "        num_intervals = int(len(outputs) // interval_size)\n",
    "        interval_wise_means = []\n",
    "\n",
    "        for i in range(num_intervals):\n",
    "            start_idx = i * interval_size\n",
    "            end_idx = (i + 1) * interval_size\n",
    "\n",
    "            interval_outputs = outputs[start_idx:end_idx]\n",
    "\n",
    "            # Initialize a dictionary to accumulate sums\n",
    "            interval_sums = {key: torch.tensor(0.0) for key in interval_outputs[0].keys()}\n",
    "\n",
    "            # Sum the values for each key in the interval\n",
    "            for output in interval_outputs:\n",
    "                for key, value in output.items():\n",
    "                    interval_sums[key] += value\n",
    "\n",
    "            # Calculate the mean for each key\n",
    "            interval_means = {key: (value / interval_size).item() for key, value in interval_sums.items()}\n",
    "            \n",
    "            interval_wise_means.append(interval_means)\n",
    "\n",
    "        return interval_wise_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
