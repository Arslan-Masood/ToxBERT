accumulate_grad_batches: 1
adam_epsilon: 1.0e-08
amp_level: O2
batch_size: 32
default_root_dir: ./checkpoints/gap_pretrain/
deterministic: 0
distributed_backend: null
fast_dev_run: 0
freeze_level: 0
gpus: 1
is_same_smiles: 0
label_column: targets
learning_rate: 3.0e-05
learning_rate_scheduler: linear_with_warmup
limit_val_batches: 1.0
masked_lm: 0
max_epochs: 20
max_position_embeddings: 512
max_seq_length: 256
min_epochs: 1
mode: regression
num_nodes: 1
num_physchem_properties: 0
num_workers: 0
output_attentions: false
output_hidden_states: false
output_size: 1
precision: 32
pretrained_model_path: null
progress_bar_refresh_rate: 25
resume_from_checkpoint: null
seed: 42
smiles_column: SMILES
test_file: ../data/hlgap/valid.csv
tiny: false
tpu_cores: null
train_file: ../data/hlgap/train.csv
val_check_interval: 0.25
valid_file: ../data/hlgap/valid.csv
vocab_size: 147
warmup_proportion: 0.1
weight_decay: 0.01
yaml_config_model_path: ./hparams.yaml
