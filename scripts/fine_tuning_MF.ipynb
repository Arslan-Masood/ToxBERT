{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "data_dir = '/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/Data_for_BERT_finetuning/'\n",
    "data = pd.read_csv(data_dir + \"complete_training_set.csv\")\n",
    "data = data.loc[:, \"Cytoplasmic alteration (Eosinophilic)\":\"hepatobiliary_disorders\"]\n",
    "data = data.fillna(-1).values\n",
    "y = torch.tensor(data)\n",
    "y_hat = torch.rand_like(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'molbert' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n molbert ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'molbert' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n molbert ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os, yaml\n",
    "from argparse import Namespace\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import wandb\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "wandb.login(key = \"27edf9c66b032c03f72d30e923276b93aa736429\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molbert.models.finetune import FinetuneSmilesMolbertModel\n",
    "from molbert.datasets.dataloading import MolbertDataLoader\n",
    "from molbert.datasets.finetune import BertFinetuneSmilesDataset_MF\n",
    "from molbert.utils.featurizer.molfeaturizer import SmilesIndexFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolbertModel(pl.LightningModule):\n",
    "    def __init__(self, args: Namespace):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.training_step_ytrue, self.training_step_ypred = [],[]\n",
    "        self.val_step_ytrue, self.val_step_ypred = [],[]\n",
    "\n",
    "        self.hparams = args\n",
    "        self.get_creterian(args)\n",
    "\n",
    "        # get model, load pretrained weights, and freeze encoder\n",
    "        self.encoder = FinetuneSmilesMolbertModel(self.hparams)\n",
    "        checkpoint = torch.load(self.hparams.pretrained_model_path, map_location=lambda storage, loc: storage)\n",
    "        self.encoder.load_state_dict(checkpoint['state_dict'], strict = False)\n",
    "                    \n",
    "        if self.hparams.freeze_level == \"complete_BERT\":\n",
    "            for param in self.encoder.model.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Task embeddings and biases\n",
    "        self.task_embedding = nn.Embedding(self.hparams.num_of_tasks, self.hparams.embedding_size)\n",
    "        self.mol_bias = nn.Embedding(self.hparams.num_mols, 1)\n",
    "        self.task_bias = nn.Embedding(self.hparams.num_of_tasks, 1)\n",
    "        \n",
    "    def forward(self, batch_inputs , mol_indices, task_indices):\n",
    "\n",
    "        mol_embeddings = self.encoder(batch_inputs)\n",
    "        mol_embeddings = mol_embeddings[\"finetune\"]\n",
    "        task_embeddings = self.task_embedding(task_indices)\n",
    "        mol_bias = self.mol_bias(mol_indices) # batch*1\n",
    "        task_bias = self.task_bias(task_indices) # batch * num_tasks * 1\n",
    "        biases_sum = mol_bias.unsqueeze(1) + task_bias # batch * num_tasks * 1\n",
    "        \n",
    "        dot_product = torch.sum(mol_embeddings.unsqueeze(1) * task_embeddings, dim=2) # [batch_size, num_tasks]\n",
    "        logits = dot_product + biases_sum.squeeze(2)   #[batch_size, num_tasks]\n",
    "        return logits, [mol_embeddings, task_embeddings, mol_bias, task_bias]\n",
    "    \n",
    "    def get_creterian(self, config):\n",
    "        # pos weights\n",
    "        \n",
    "        pos_weights = pd.read_csv(config[\"pos_weights\"])\n",
    "        if self.hparams.num_of_tasks == 1:\n",
    "            pos_weights = pos_weights.set_index(\"Targets\").reindex([config[\"selected_tasks\"]]).weights.values\n",
    "        else:\n",
    "            pos_weights = pos_weights.set_index(\"Targets\").reindex(config[\"selected_tasks\"]).weights.values\n",
    "        pos_weights = (config[\"alpha\"] * pos_weights) + (1 - config[\"alpha\"])*1\n",
    "        self.pos_weights = torch.tensor(pos_weights, device = config[\"device\"])\n",
    "\n",
    "        # class weights\n",
    "        if self.hparams.num_of_tasks > 1:\n",
    "            class_weights = pd.read_csv(config[\"class_weights\"])\n",
    "            class_weights = class_weights.set_index(\"Targets\").reindex(config[\"selected_tasks\"]).weights.values\n",
    "            class_weights = (config[\"beta\"] * class_weights) + (1 - config[\"beta\"])*1\n",
    "            self.class_weights = torch.tensor(class_weights, device = config[\"device\"])\n",
    "        else:\n",
    "            self.class_weights = torch.tensor([1.0], device = config[\"device\"])\n",
    "\n",
    "        # train_weighted loss, validation no weights\n",
    "        self.weighted_creterien =  nn.BCEWithLogitsLoss(reduction=\"none\", \n",
    "                                                        pos_weight= self.pos_weights,\n",
    "                                                        weight= self.class_weights)\n",
    "        \n",
    "        self.non_weighted_creterian =  nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optim == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(self.parameters(), \n",
    "                                             lr=self.hparams.lr)\n",
    "        if self.hparams.optim == 'Adam':\n",
    "            self.optimizer = torch.optim.Adam(self.parameters(), \n",
    "                                              #weight_decay = self.l2_lambda,\n",
    "                                             lr=self.hparams.lr)\n",
    "        \n",
    "        if self.hparams.lr_schedulers == \"CosineAnnealingLR\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, \n",
    "                                                                        T_max = 10, \n",
    "                                                                        eta_min=1e-6) \n",
    "            return {\"optimizer\": self.optimizer, \n",
    "                    \"lr_scheduler\": self.scheduler}\n",
    "        \n",
    "        if self.hparams.lr_schedulers == \"ReduceLROnPlateau\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer,\n",
    "                                                                        verbose=True,\n",
    "                                                                        patience=15,\n",
    "                                                                        min_lr=1e-6,\n",
    "                                                                        mode = 'min')\n",
    "            return {\n",
    "            'optimizer':  self.optimizer,\n",
    "            'lr_scheduler':  self.scheduler, # Changed scheduler to lr_scheduler\n",
    "            'monitor': 'val_BCE_loss'\n",
    "            }\n",
    "    \n",
    "    def compute_regularization(self):\n",
    "        device = torch.device('cuda')\n",
    "        encoder_reg = torch.tensor(0., requires_grad=True, device=device)\n",
    "        task_emb_reg = torch.tensor(0., requires_grad=True, device=device)\n",
    "\n",
    "        # l2: Apply only on weights, exclude bias\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                encoder_reg = encoder_reg + torch.norm(param, p=2)\n",
    "\n",
    "        # l1: Apply only on weights, exclude bias\n",
    "        for name, param in self.task_embedding.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                task_emb_reg = task_emb_reg + torch.norm(param, p=1)\n",
    "                \n",
    "        return encoder_reg, task_emb_reg\n",
    "    \n",
    "    def _compute_loss(self, y, y_hat):\n",
    "        if self.hparams.num_of_tasks == 1:\n",
    "            y = y.unsqueeze(1)\n",
    "        # compute losses, wiht masking\n",
    "        if self.hparams.missing == 'nan':\n",
    "            nan_mask = torch.isnan(y)\n",
    "            y[nan_mask] = -1\n",
    "            #y = torch.nan_to_num(y, nan = -1), for newer version\n",
    "        \n",
    "        # masks\n",
    "        valid_label_mask = (y != -1).float()\n",
    "        pos_label_mask = (y == 1)\n",
    "        negative_label_mask = (y == 0)\n",
    "\n",
    "        weighted_loss = self.weighted_creterien(y_hat, y) * valid_label_mask\n",
    "        Non_weighted_loss = self.non_weighted_creterian(y_hat, y) * valid_label_mask\n",
    "        \n",
    "        # Non_weighted_loss, positive negative loss\n",
    "        pos_loss = Non_weighted_loss * pos_label_mask\n",
    "        neg_loss = Non_weighted_loss * negative_label_mask\n",
    "        pos_loss = pos_loss.sum() / pos_label_mask.sum()\n",
    "        neg_loss = neg_loss.sum() / negative_label_mask.sum()\n",
    "    \n",
    "        # compute mean loss\n",
    "        Non_weighted_loss = Non_weighted_loss.sum() / valid_label_mask.sum()\n",
    "        weighted_loss = weighted_loss.sum() / valid_label_mask.sum()\n",
    "\n",
    "        encoder_reg, task_emb_reg = self.compute_regularization()\n",
    "        encoder_reg = self.hparams.l2_lambda*encoder_reg\n",
    "        \n",
    "        task_emb_reg = self.hparams.l1_lambda*task_emb_reg\n",
    "        total_reg = encoder_reg + task_emb_reg\n",
    "\n",
    "        total_loss = weighted_loss + total_reg\n",
    "\n",
    "        return total_loss, weighted_loss, Non_weighted_loss,total_reg, pos_loss, neg_loss\n",
    "    \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # compute forward pass\n",
    "        (batch_inputs, batch_labels), _ = batch\n",
    "\n",
    "        y = batch_labels[\"finetune\"].squeeze()\n",
    "        mol_indices = batch_labels[\"mol_indices\"]\n",
    "        task_indices = batch_labels[\"task_indices\"]\n",
    "\n",
    "        y_hat, _ = self.forward(batch_inputs,\n",
    "                                        mol_indices,\n",
    "                                        task_indices\n",
    "                                        )\n",
    "\n",
    "        # compute loss\n",
    "        total_loss, weighted_loss, Non_weighted_loss,l2_reg_loss, pos_loss, neg_loss = self._compute_loss(y, y_hat)  \n",
    "        self.training_step_ytrue.append(y.long().cpu())\n",
    "        self.training_step_ypred.append(torch.sigmoid(y_hat).cpu())\n",
    "\n",
    "        return {\"loss\": total_loss,\n",
    "                \"weighted_loss\":weighted_loss,\n",
    "                \"Non_weighted_loss\":Non_weighted_loss,\n",
    "                \"l2_reg_loss\":l2_reg_loss, \n",
    "                \"pos_loss\":pos_loss, \n",
    "                \"neg_loss\":neg_loss\n",
    "                }\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # compute forward pass\n",
    "        (batch_inputs, batch_labels), _ = batch\n",
    "\n",
    "        y = batch_labels[\"finetune\"].squeeze()\n",
    "        mol_indices = batch_labels[\"mol_indices\"]\n",
    "        task_indices = batch_labels[\"task_indices\"]\n",
    "\n",
    "        y_hat, _ = self.forward(batch_inputs,\n",
    "                                mol_indices,\n",
    "                                task_indices\n",
    "                                )\n",
    "\n",
    "        # compute loss\n",
    "        total_loss, weighted_loss, Non_weighted_loss,l2_reg_loss, pos_loss, neg_loss = self._compute_loss(y, y_hat)  \n",
    "        self.val_step_ytrue.append(y.long().cpu())\n",
    "        self.val_step_ypred.append(torch.sigmoid(y_hat).cpu())\n",
    "        return {\"loss\": total_loss,\n",
    "                \"weighted_loss\":weighted_loss,\n",
    "                \"Non_weighted_loss\":Non_weighted_loss,\n",
    "                \"l2_reg_loss\":l2_reg_loss, \n",
    "                \"pos_loss\":pos_loss, \n",
    "                \"neg_loss\":neg_loss\n",
    "                }\n",
    "    \n",
    "    def on_epoch_start(self):\n",
    "        # Check if current epoch is greater than or equal to the desired epoch to unfreeze\n",
    "        if self.current_epoch >= self.hparams.unfreeze_epoch:\n",
    "            self.unfreeze_model()\n",
    "\n",
    "            # Decrease the learning rate\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = self.hparams.BERT_lr\n",
    "            \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, \n",
    "                                                                        last_epoch = self.scheduler.last_epoch,\n",
    "                                                                        T_max = 10, \n",
    "                                                                        eta_min=1e-6)\n",
    "                \n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_weighted_loss = torch.stack([x['weighted_loss'] for x in outputs]).mean()\n",
    "        avg_non_weighted_loss = torch.stack([x['Non_weighted_loss'] for x in outputs]).mean()\n",
    "        avg_l2_reg_loss = torch.stack([x['l2_reg_loss'] for x in outputs]).mean()\n",
    "        avg_pos_loss = torch.stack([x['pos_loss'] for x in outputs]).mean()\n",
    "        avg_neg_loss = torch.stack([x['neg_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\n",
    "                    'train_total_loss': avg_loss,\n",
    "                    'train_weighted_loss': avg_weighted_loss,\n",
    "                    'train_Non_weighted_loss': avg_non_weighted_loss,\n",
    "                    'train_l2_reg_loss': avg_l2_reg_loss,\n",
    "                    'train_pos_loss': avg_pos_loss,\n",
    "                    'train_neg_loss': avg_neg_loss\n",
    "                    }\n",
    "        wandb.log(tensorboard_logs)\n",
    "\n",
    "        # Log the learning rate at the end of each epoch\n",
    "        lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        wandb.log({'learning_rate': lr})\n",
    "        \n",
    "        # Collect predictions and true labels for the complete training set\n",
    "        train_true = torch.cat(self.training_step_ytrue, dim=0)\n",
    "        train_preds = torch.cat(self.training_step_ypred, dim=0)\n",
    "\n",
    "        score_list =  self.compute_metrics(train_true, train_preds)\n",
    "        metric = ['roc_score', 'blc_acc', 'sensitivity', 'specificity', 'AUPR']\n",
    "            \n",
    "        for i, score in enumerate(score_list):\n",
    "                wandb.log({f'train_{metric[i]}':score.item()})\n",
    "        \n",
    "        # Clear the lists to free memory for the next epoch\n",
    "        self.training_step_ytrue.clear()\n",
    "        self.training_step_ypred.clear()\n",
    "        del train_true,train_preds\n",
    "\n",
    "        return {\"avg_loss\":avg_loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_weighted_loss = torch.stack([x['weighted_loss'] for x in outputs]).mean()\n",
    "        avg_non_weighted_loss = torch.stack([x['Non_weighted_loss'] for x in outputs]).mean()\n",
    "        avg_l2_reg_loss = torch.stack([x['l2_reg_loss'] for x in outputs]).mean()\n",
    "        avg_pos_loss = torch.stack([x['pos_loss'] for x in outputs]).mean()\n",
    "        avg_neg_loss = torch.stack([x['neg_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\n",
    "                    'val_total_loss': avg_loss,\n",
    "                    'val_weighted_loss': avg_weighted_loss,\n",
    "                    'val_Non_weighted_loss': avg_non_weighted_loss,\n",
    "                    'val_l2_reg_loss': avg_l2_reg_loss,\n",
    "                    'val_pos_loss': avg_pos_loss,\n",
    "                    'val_neg_loss': avg_neg_loss\n",
    "                    }\n",
    "        wandb.log(tensorboard_logs)\n",
    "\n",
    "        #Collect predictions and true labels for the complete training set\n",
    "        val_true = torch.cat(self.val_step_ytrue, dim=0)\n",
    "        val_preds = torch.cat(self.val_step_ypred, dim=0)\n",
    "\n",
    "        score_list =  self.compute_metrics(val_true,val_preds)\n",
    "        metric = ['roc_score', 'blc_acc', 'sensitivity', 'specificity', 'AUPR']\n",
    "            \n",
    "        for i, score in enumerate(score_list):\n",
    "            wandb.log({f'val_{metric[i]}':score.item()})\n",
    "\n",
    "        # Clear the lists to free memory for the next epoch\n",
    "        self.val_step_ytrue.clear()\n",
    "        self.val_step_ypred.clear()\n",
    "        del val_true, val_preds\n",
    "\n",
    "    def compute_metrics(self, y_true, y_pred): \n",
    "        self.eval()\n",
    "\n",
    "        targets =  y_true.cpu().detach().tolist()\n",
    "        preds = y_pred.cpu().detach().tolist()\n",
    "\n",
    "        targets = np.array(targets).reshape(-1,self.hparams.num_of_tasks)\n",
    "        preds = np.array(preds).reshape(-1,self.hparams.num_of_tasks)\n",
    "\n",
    "        #if self.hparams.missing == 'nan':\n",
    "        #    mask = ~np.isnan(targets)\n",
    "        \n",
    "        mask = (targets != -1)\n",
    "\n",
    "        roc_score, blc_acc, sensitivity, specificity, AUPR, f1_score, average_precision = [],[],[],[],[],[],[]\n",
    "        for i in range(self.hparams.num_of_tasks):\n",
    "                \n",
    "                # get valid targets, and convert logits to prob\n",
    "                valid_targets = targets[:,i][mask[:,i]]\n",
    "                valid_preds = expit(preds[:,i][mask[:,i]])\n",
    "                try:\n",
    "                    # ROC_AUC\n",
    "                    fpr, tpr, th = roc_curve(valid_targets, valid_preds)\n",
    "                    roc_score.append(auc(fpr, tpr))\n",
    "\n",
    "                    # Balanced accuracy\n",
    "                    balanced_accuracy = (tpr + (1 - fpr)) / 2\n",
    "                    blc_acc.append(np.max(balanced_accuracy))\n",
    "\n",
    "                    # sensitivity, specificity\n",
    "                    optimal_threshold_index = np.argmax(balanced_accuracy)\n",
    "                    optimal_threshold = th[optimal_threshold_index]\n",
    "                    sensitivity.append(tpr[optimal_threshold_index])\n",
    "                    specificity.append(1 - fpr[optimal_threshold_index])\n",
    "\n",
    "                    # AUPR, F1\n",
    "                    precision, recall, thresholds = precision_recall_curve(valid_targets, valid_preds)\n",
    "                    AUPR.append(auc(recall, precision))\n",
    "                    \n",
    "                except:\n",
    "                    roc_score.append(np.nan)\n",
    "                    #print('Performance metric is null')\n",
    "                \n",
    "        self.train()\n",
    "        return np.nanmean(roc_score), np.nanmean(blc_acc), np.nanmean(sensitivity), np.nanmean(specificity), np.nanmean(AUPR)\n",
    "\n",
    "    \n",
    "    def prob_to_labels(self, pred, threshold):\n",
    "\t    return (pred >= threshold).astype('int')\n",
    "\n",
    "    def unfreeze_model(self):\n",
    "        for param in self.encoder.model.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_dict\n",
    "model_weights_dir = '/projects/home/mmasood1/Model_weights/preclinical_clinical/BERT/'\n",
    "pretrained_model_path = '/projects/home/mmasood1/TG GATE/MolBERT/molbert/molbert_100epochs/molbert_100epochs/checkpoints/last.ckpt'\n",
    "data_dir = '/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/Data_for_BERT_finetuning/'\n",
    "pos_weights = \"/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/06_10_2023/pos_weights.csv\"\n",
    "class_weights = \"/projects/home/mmasood1/arslan_data_repository/Mix_clinical_pre_clinical/06_10_2023/target_weights.csv\"\n",
    "metadata_dir = \"/projects/home/mmasood1/trained_model_predictions/SIDER_PreClinical/BERT_finetune/MF/\"\n",
    "model_dir = os.path.dirname(os.path.dirname(pretrained_model_path))\n",
    "hparams_path = os.path.join(model_dir, 'hparams.yaml')\n",
    "\n",
    "# load config\n",
    "with open(hparams_path) as yaml_file:\n",
    "    config_dict = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "config_dict['project_name'] = \"BERT_finetuning_MF\"\n",
    "config_dict['model_name'] = \"First_train_head_then_finetune_encoder\"\n",
    "\n",
    "config_dict['model_weights_dir'] = model_weights_dir\n",
    "config_dict['pretrained_model_path'] = pretrained_model_path\n",
    "config_dict[\"metadata_dir\"] = metadata_dir\n",
    "config_dict['pos_weights'] = pos_weights\n",
    "config_dict['class_weights'] = class_weights\n",
    "\n",
    "config_dict['data_dir'] = data_dir\n",
    "config_dict['train_file'] = data_dir + \"complete_training_set.csv\"\n",
    "config_dict['valid_file'] = data_dir + \"complete_test_set.csv\"\n",
    "config_dict['test_file'] = data_dir + \"complete_test_set.csv\"\n",
    "\n",
    "config_dict['mode'] = 'classification'\n",
    "config_dict['alpha'] = 1.0\n",
    "config_dict['beta'] = 0.0\n",
    "config_dict['epochs'] = 310\n",
    "config_dict['unfreeze_epoch'] = 210\n",
    "config_dict[\"l2_lambda\"] = 0.0\n",
    "config_dict[\"l1_lambda\"] = 0.0\n",
    "config_dict['embedding_size'] = 50\n",
    "config_dict[\"freeze_level\"] = \"complete_BERT\"\n",
    "\n",
    "config_dict['optim'] = 'Adam'#SGD\n",
    "config_dict['lr_schedulers'] = \"CosineAnnealingLR\"\n",
    "config_dict['lr'] = 1e-3\n",
    "config_dict[\"BERT_lr\"] = 3e-5\n",
    "config_dict[\"batch_size\"] = 64\n",
    "\n",
    "\n",
    "config_dict['missing'] = 'nan'\n",
    "config_dict['compute_metric_after_n_epochs'] = 5\n",
    "config_dict['return_trainer'] = True\n",
    "config_dict['EarlyStopping'] = False\n",
    "\n",
    "config_dict[\"accelerator\"] = \"gpu\"\n",
    "config_dict[\"gpu\"] =  [0]\n",
    "config_dict[\"device\"] = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "data = pd.read_csv(config_dict['train_file'])\n",
    "try:\n",
    "    data.drop(['Scafold','fold'], axis = 1, inplace = True)\n",
    "except:\n",
    "    pass\n",
    "target_names = data.loc[:,\"Cytoplasmic alteration (Basophilic/glycogen depletion)\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "\n",
    "#target_names = data.loc[:,\"DILI_binary\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "config_dict[\"output_size\"] = len(target_names)\n",
    "config_dict[\"label_column\"] = target_names\n",
    "\n",
    "config_dict[\"num_of_tasks\"] = len(target_names)\n",
    "config_dict[\"selected_tasks\"] = target_names\n",
    "config_dict['num_mols'] = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "featurizer = SmilesIndexFeaturizer.bert_smiles_index_featurizer(config_dict[\"max_seq_length\"], permute = False)\n",
    "train_dataset = BertFinetuneSmilesDataset_MF(\n",
    "            input_path= config_dict['train_file'],\n",
    "            featurizer=featurizer,\n",
    "            single_seq_len=config_dict[\"max_seq_length\"],\n",
    "            total_seq_len=config_dict[\"max_seq_length\"],\n",
    "            label_column=config_dict[\"label_column\"],\n",
    "            is_same=False,\n",
    "            inference_mode=True,\n",
    "        )\n",
    "\n",
    "validation_dataset = BertFinetuneSmilesDataset_MF(\n",
    "            input_path= config_dict['valid_file'],\n",
    "            featurizer=featurizer,\n",
    "            single_seq_len=config_dict[\"max_seq_length\"],\n",
    "            total_seq_len=config_dict[\"max_seq_length\"],\n",
    "            label_column=config_dict[\"label_column\"],\n",
    "            is_same=False,\n",
    "            inference_mode=True,\n",
    "        )\n",
    "\n",
    "test_dataset = BertFinetuneSmilesDataset_MF(\n",
    "            input_path= config_dict['test_file'],\n",
    "            featurizer=featurizer,\n",
    "            single_seq_len=config_dict[\"max_seq_length\"],\n",
    "            total_seq_len=config_dict[\"max_seq_length\"],\n",
    "            label_column=config_dict[\"label_column\"],\n",
    "            is_same=False,\n",
    "            inference_mode=True,\n",
    ")\n",
    "########################################################################\n",
    "train_dataloader = MolbertDataLoader(train_dataset, \n",
    "                                    batch_size=config_dict[\"batch_size\"],\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=4, \n",
    "                                    shuffle = True)\n",
    "\n",
    "validation_dataloader = MolbertDataLoader(validation_dataset, \n",
    "                                    batch_size=config_dict[\"batch_size\"],\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=4, \n",
    "                                    shuffle = False)\n",
    "\n",
    "test_dataloader = MolbertDataLoader(test_dataset, \n",
    "                                    batch_size=config_dict[\"batch_size\"],\n",
    "                                    pin_memory=False,\n",
    "                                    num_workers=4, \n",
    "                                    shuffle = False)\n",
    "\n",
    "config_dict[\"num_batches\"] = len(train_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_init_model(model, \n",
    "                     config, \n",
    "                     train_dataloader,\n",
    "                     val_dataloader, \n",
    "                     model_type):\n",
    "    \n",
    "    default_root_dir = config[\"model_weights_dir\"]\n",
    "    max_epochs = config[\"epochs\"]\n",
    "    return_trainer = config[\"return_trainer\"]\n",
    "\n",
    "    # logger\n",
    "    model = model(config)\n",
    "    wandb_logger = WandbLogger( \n",
    "                        name = config[\"model_name\"],\n",
    "                        save_dir = '/projects/home/mmasood1/Model_weights',\n",
    "                        project= config[\"project_name\"],\n",
    "                        entity=\"arslan_masood\", \n",
    "                        log_model='all',\n",
    "                        )\n",
    "    # trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs= int(max_epochs),\n",
    "        gpus = -1,\n",
    "        logger = wandb_logger,\n",
    "        default_root_dir=default_root_dir)\n",
    "\n",
    "    # model fitting \n",
    "    trainer.fit(model, \n",
    "                train_dataloader = train_dataloader,\n",
    "                val_dataloaders = val_dataloader,\n",
    "                )\n",
    "    if return_trainer:\n",
    "        return model, trainer\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "INFO: GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                   | Type                       | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | weighted_creterien     | BCEWithLogitsLoss          | 0     \n",
      "1 | non_weighted_creterian | BCEWithLogitsLoss          | 0     \n",
      "2 | encoder                | FinetuneSmilesMolbertModel | 85 M  \n",
      "3 | task_embedding         | Embedding                  | 2 K   \n",
      "4 | mol_bias               | Embedding                  | 1 K   \n",
      "5 | task_bias              | Embedding                  | 50    \n",
      "INFO: \n",
      "  | Name                   | Type                       | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | weighted_creterien     | BCEWithLogitsLoss          | 0     \n",
      "1 | non_weighted_creterian | BCEWithLogitsLoss          | 0     \n",
      "2 | encoder                | FinetuneSmilesMolbertModel | 85 M  \n",
      "3 | task_embedding         | Embedding                  | 2 K   \n",
      "4 | mol_bias               | Embedding                  | 1 K   \n",
      "5 | task_bias              | Embedding                  | 50    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  76%|███████▌  | 19/25 [00:07<00:02,  2.58it/s, loss=2.402, v_num=fkst3g0z]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 20 batches in order to train on 20 batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 25/25 [00:09<00:00,  2.66it/s, loss=2.360, v_num=fkst3g0z]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 5 batches in order to train on 5 batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  76%|███████▌  | 19/25 [00:07<00:02,  2.63it/s, loss=1.592, v_num=fkst3g0z]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 20 batches in order to train on 20 batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 25/25 [00:09<00:00,  2.70it/s, loss=1.605, v_num=fkst3g0z]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 5 batches in order to train on 5 batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 25/25 [00:09<00:00,  2.65it/s, loss=1.605, v_num=fkst3g0z]\n"
     ]
    }
   ],
   "source": [
    "trained_model, trainer = wandb_init_model(model = MolbertModel, \n",
    "                                                                train_dataloader = train_dataloader,\n",
    "                                                                val_dataloader =validation_dataloader,\n",
    "                                                                config = config_dict, \n",
    "                                                                model_type = 'MLP')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config_dict[\"metadata_dir\"] + \"predicitons/\"\n",
    "result_dir = config_dict[\"metadata_dir\"] + \"Results/\"  \n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch finished. Accessed 5 batches in order to train on 5 batches.\n"
     ]
    }
   ],
   "source": [
    "model = trained_model.eval()\n",
    "config = config_dict\n",
    "device = torch.device('cuda')\n",
    "model = model.cpu() \n",
    "\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for batch in validation_dataloader:\n",
    "    \n",
    "    (batch_inputs, batch_labels), _ = batch\n",
    "    y = batch_labels[\"finetune\"].squeeze()\n",
    "    mol_indices = batch_labels[\"mol_indices\"].cpu()\n",
    "    task_indices = batch_labels[\"task_indices\"].cpu()\n",
    "\n",
    "    y_hat, embeddings = model(batch_inputs,mol_indices,task_indices)\n",
    "\n",
    "    y_true_list.append(y.cpu())\n",
    "    y_pred_list.append(y_hat.cpu())\n",
    "\n",
    "y = torch.cat(y_true_list, dim=0)\n",
    "y_hat = torch.cat(y_pred_list, dim=0)\n",
    "\n",
    "if config[\"num_of_tasks\"] > 1:\n",
    "    y = pd.DataFrame(y.cpu().detach().numpy())\n",
    "    y_hat = pd.DataFrame(y_hat.cpu().detach().numpy())\n",
    "    y.columns = config['selected_tasks']\n",
    "    y_hat.columns = config['selected_tasks']\n",
    "else:\n",
    "    y = pd.DataFrame({config[\"selected_tasks\"]: y.cpu().detach().numpy()})\n",
    "    y_hat = pd.DataFrame({config[\"selected_tasks\"]: y_hat.cpu().detach().numpy().reshape(-1)})\n",
    "\n",
    "y.to_csv(data_dir + 'y_true_test.csv',index=False)\n",
    "y_hat.to_csv(data_dir + 'y_pred_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################3\n",
    "# Compute compute_binary_classification_metrics: Multitask\n",
    "######################################################################################\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import average_precision_score, f1_score\n",
    "\n",
    "def prob_to_labels(pred, threshold):\n",
    "\t    return (pred >= threshold).astype('int')\n",
    "\n",
    "def compute_binary_classification_metrics_MT(y_true, y_pred_proba, \n",
    "                                             missing):\n",
    "    \"\"\"\n",
    "    Compute various metrics for binary classification.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): Binary labels (0 or 1).\n",
    "        y_pred_proba (array-like): Predictive probabilities for the positive class.\n",
    "        threshold (float, optional): Threshold value for classification. Default is 0.5.\n",
    "    \n",
    "   Returns:\n",
    "        pandas.DataFrame: DataFrame containing the computed metrics for each task (accuracy, ROC AUC, average precision, MCC, F1-score, random precision, gain in average precision).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        num_tasks = y_true.shape[1]  # Get the number of tasks\n",
    "    except:\n",
    "        num_tasks = 1\n",
    "    metrics_list = []\n",
    "\n",
    "    for i in range(num_tasks):\n",
    "        if num_tasks > 1:\n",
    "            y_true_task = y_true[:, i]\n",
    "            y_pred_proba_task = y_pred_proba[:, i]\n",
    "        else:\n",
    "            y_true_task = y_true\n",
    "            y_pred_proba_task = y_pred_proba\n",
    "            \n",
    "        # Apply masking\n",
    "        if missing == 'nan':\n",
    "            mask = ~np.isnan(y_true_task)\n",
    "        if missing == -1:\n",
    "            mask = (y_true_task != -1)\n",
    "\n",
    "        y_true_task = y_true_task[mask]\n",
    "        y_pred_proba_task = y_pred_proba_task[mask]\n",
    "\n",
    "        metrics_task = {}\n",
    "        try:\n",
    "            # ROC AUC\n",
    "            fpr, tpr, th = roc_curve(y_true_task, y_pred_proba_task)\n",
    "            metrics_task['roc_auc'] = auc(fpr, tpr)\n",
    "\n",
    "            # Balanced accuracy\n",
    "            balanced_accuracy = (tpr + (1 - fpr)) / 2\n",
    "            metrics_task['balanced_acc'] = np.max(balanced_accuracy)\n",
    "            \n",
    "            # sensitivity, specificity\n",
    "            optimal_threshold_index = np.argmax(balanced_accuracy)\n",
    "            optimal_threshold = th[optimal_threshold_index]\n",
    "            metrics_task['sensitivity'] = tpr[optimal_threshold_index]\n",
    "            metrics_task['specificity'] = 1 - fpr[optimal_threshold_index]\n",
    "\n",
    "        except:\n",
    "            metrics_task['roc_auc'] = np.nan\n",
    "            metrics_task['sensitivity']= np.nan\n",
    "            metrics_task['specificity']= np.nan\n",
    "        try:\n",
    "            precision, recall, thresholds = precision_recall_curve(y_true_task, y_pred_proba_task)\n",
    "            metrics_task['AUPR'] = auc(recall, precision)\n",
    "            f1 = [f1_score(y_true_task, prob_to_labels(y_pred_proba_task, t)) for t in thresholds]\n",
    "            metrics_task['f1_score'] = np.max(f1)\n",
    "\n",
    "            metrics_task['average_precision'] = average_precision_score(y_true_task, y_pred_proba_task)\n",
    "        except:\n",
    "            metrics_task['AUPR'] = np.nan\n",
    "            metrics_task['f1_score'] = np.nan\n",
    "        \n",
    "\n",
    "        metrics_list.append(metrics_task)\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    col = ['balanced_acc', 'f1_score','specificity','sensitivity', 'roc_auc','AUPR', 'average_precision']\n",
    "    \n",
    "    return metrics_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "data = pd.read_csv(config_dict[\"data_dir\"] + \"train_fold0.csv\")\n",
    "target_names = data.loc[:,\"Cytoplasmic alteration (Basophilic/glycogen depletion)\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "#target_names = data.loc[:,\"DILI_binary\":\"hepatobiliary_disorders\"].columns.tolist()\n",
    "config[\"num_of_tasks\"] = len(target_names)\n",
    "config[\"selected_tasks\"] = target_names\n",
    "\n",
    "preclinical_tasks = config[\"selected_tasks\"][:20]\n",
    "clinical_tasks = config[\"selected_tasks\"][20:]\n",
    "\n",
    "pathological_tasks = ['Cytoplasmic alteration (Basophilic/glycogen depletion)',\n",
    "                        'Cytoplasmic alteration (Eosinophilic)',\n",
    "                        'Extramedullary Hematopoiesis',\n",
    "                        'Hypertrophy, hepatocellular',\n",
    "                        'Hypertrophy/Hyperplasia',\n",
    "                        'Increased mitoses',\n",
    "                        'Infiltration, Mononuclear',\n",
    "                        'Necrosis',\n",
    "                        'Pigmentation (pigment deposition)',\n",
    "                        'Single Cell Necrosis',\n",
    "                        'Vacuolation',\n",
    "                        'DILI_binary']\n",
    "\n",
    "blood_tasks = ['ALP(IU/L)',\n",
    "                'AST(IU/L)',\n",
    "                'ALT(IU/L)',\n",
    "                'GTP(IU/L)',\n",
    "                'TC(mg/dL)',\n",
    "                'TG(mg/dL)',\n",
    "                'TBIL(mg/dL)',\n",
    "                'DBIL(mg/dL)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_binary_classification_metrics_MT(y_true = y[config['selected_tasks']].values, \n",
    "                                                    y_pred_proba = y_hat[config['selected_tasks']].values,\n",
    "                                                                        missing = 'nan')\n",
    "metrics.insert(0, 'Tasks', target_names)\n",
    "mean_preformances = {\"pathology_mean\": metrics[metrics.Tasks.isin(pathological_tasks)].iloc[:,1:].mean(),\n",
    "                    \"blood_mean\": metrics[metrics.Tasks.isin(blood_tasks)].iloc[:,1:].mean(),\n",
    "                    \"preclinical_mean\": metrics[metrics.Tasks.isin(preclinical_tasks)].iloc[:,1:].mean(),\n",
    "                    \"clinical_mean\": metrics[metrics.Tasks.isin(clinical_tasks)].iloc[:,1:].mean(),\n",
    "                    \"combined_ex_BM\":metrics[metrics.Tasks.isin(clinical_tasks + pathological_tasks)].iloc[:,1:].mean(),\n",
    "                    \"combined_all\": metrics.iloc[:,1:].mean()}\n",
    "mean_preformances = pd.DataFrame(mean_preformances).T\n",
    "mean_preformances = mean_preformances.rename_axis('Tasks').reset_index()\n",
    "metrics = pd.concat([metrics, mean_preformances], ignore_index=True) \n",
    "metrics.to_csv(result_dir + f'val_metric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tasks</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>average_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>blood_mean</td>\n",
       "      <td>0.769882</td>\n",
       "      <td>0.304288</td>\n",
       "      <td>0.668931</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>0.740225</td>\n",
       "      <td>0.180937</td>\n",
       "      <td>0.211814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>preclinical_mean</td>\n",
       "      <td>0.762112</td>\n",
       "      <td>0.278317</td>\n",
       "      <td>0.662165</td>\n",
       "      <td>0.862060</td>\n",
       "      <td>0.707930</td>\n",
       "      <td>0.156609</td>\n",
       "      <td>0.189075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>clinical_mean</td>\n",
       "      <td>0.622902</td>\n",
       "      <td>0.334131</td>\n",
       "      <td>0.577154</td>\n",
       "      <td>0.668649</td>\n",
       "      <td>0.591154</td>\n",
       "      <td>0.221321</td>\n",
       "      <td>0.233160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>combined_ex_BM</td>\n",
       "      <td>0.661196</td>\n",
       "      <td>0.313237</td>\n",
       "      <td>0.600154</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.618367</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.216233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>combined_all</td>\n",
       "      <td>0.678586</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.611158</td>\n",
       "      <td>0.746013</td>\n",
       "      <td>0.637864</td>\n",
       "      <td>0.195436</td>\n",
       "      <td>0.215526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tasks  balanced_acc  f1_score  specificity  sensitivity  \\\n",
       "51        blood_mean      0.769882  0.304288     0.668931     0.870833   \n",
       "52  preclinical_mean      0.762112  0.278317     0.662165     0.862060   \n",
       "53     clinical_mean      0.622902  0.334131     0.577154     0.668649   \n",
       "54    combined_ex_BM      0.661196  0.313237     0.600154     0.722238   \n",
       "55      combined_all      0.678586  0.311805     0.611158     0.746013   \n",
       "\n",
       "     roc_auc      AUPR  average_precision  \n",
       "51  0.740225  0.180937           0.211814  \n",
       "52  0.707930  0.156609           0.189075  \n",
       "53  0.591154  0.221321           0.233160  \n",
       "54  0.618367  0.198198           0.216233  \n",
       "55  0.637864  0.195436           0.215526  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
